{
  "adapter_name": "banking_expert",
  "model": "Qwen/Qwen2.5-1.5B",
  "rank": 32,
  "alpha": 64.0,
  "target_modules": [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj"
  ],
  "total_steps": 2000,
  "final_loss": 2.867584466934204,
  "best_loss": 1.1217055320739746,
  "total_time_seconds": 1580.1,
  "dataset_size": 30000,
  "metrics": [
    {
      "step": 7,
      "optim_step": 1,
      "loss": 2.6787710189819336,
      "grad_norm": 7.960289001464844,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 544.4127999944612,
      "epsilon_spent": 0.3753615202023788,
      "total_epsilon": 0.3753615202023788
    },
    {
      "step": 15,
      "optim_step": 2,
      "loss": 3.572779655456543,
      "grad_norm": 13.831941604614258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 716.5910999901826,
      "epsilon_spent": 0.3910347543120258,
      "total_epsilon": 0.3910347543120258
    },
    {
      "step": 23,
      "optim_step": 3,
      "loss": 4.778454303741455,
      "grad_norm": 19.189544677734375,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 535.5299999937415,
      "epsilon_spent": 0.4008597852588415,
      "total_epsilon": 0.4008597852588415
    },
    {
      "step": 31,
      "optim_step": 4,
      "loss": 2.06003475189209,
      "grad_norm": 1.2257417440414429,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 479.7711999999592,
      "epsilon_spent": 0.4076469527179957,
      "total_epsilon": 0.4076469527179957
    },
    {
      "step": 39,
      "optim_step": 5,
      "loss": 3.410095691680908,
      "grad_norm": 16.04225730895996,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 438.1762999983039,
      "epsilon_spent": 0.4136176453560761,
      "total_epsilon": 0.4136176453560761
    },
    {
      "step": 47,
      "optim_step": 6,
      "loss": 3.3343353271484375,
      "grad_norm": 15.976691246032715,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 430.9279000008246,
      "epsilon_spent": 0.4187513883796352,
      "total_epsilon": 0.4187513883796352
    },
    {
      "step": 55,
      "optim_step": 7,
      "loss": 3.631190538406372,
      "grad_norm": 17.925817489624023,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 430.7035999954678,
      "epsilon_spent": 0.42237704813848115,
      "total_epsilon": 0.42237704813848115
    },
    {
      "step": 63,
      "optim_step": 8,
      "loss": 3.6188979148864746,
      "grad_norm": 20.11319923400879,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 434.46340000082273,
      "epsilon_spent": 0.4260027078973271,
      "total_epsilon": 0.4260027078973271
    },
    {
      "step": 71,
      "optim_step": 9,
      "loss": 4.712276935577393,
      "grad_norm": 15.03431224822998,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 448.3144999976503,
      "epsilon_spent": 0.42962836765617296,
      "total_epsilon": 0.42962836765617296
    },
    {
      "step": 79,
      "optim_step": 10,
      "loss": 3.956186056137085,
      "grad_norm": 12.966254234313965,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 437.6538999931654,
      "epsilon_spent": 0.4331823249477652,
      "total_epsilon": 0.4331823249477652
    },
    {
      "step": 87,
      "optim_step": 11,
      "loss": 4.151366710662842,
      "grad_norm": 19.420799255371094,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 452.9684000008274,
      "epsilon_spent": 0.43538296649621944,
      "total_epsilon": 0.43538296649621944
    },
    {
      "step": 95,
      "optim_step": 12,
      "loss": 4.259800910949707,
      "grad_norm": 18.784622192382812,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 643.9494000078412,
      "epsilon_spent": 0.4375836080446737,
      "total_epsilon": 0.4375836080446737
    },
    {
      "step": 103,
      "optim_step": 13,
      "loss": 3.1619832515716553,
      "grad_norm": 16.036500930786133,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 773.9453999965917,
      "epsilon_spent": 0.439784249593128,
      "total_epsilon": 0.439784249593128
    },
    {
      "step": 111,
      "optim_step": 14,
      "loss": 1.7315421104431152,
      "grad_norm": 3.302685260772705,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 742.6069999928586,
      "epsilon_spent": 0.44198489114158224,
      "total_epsilon": 0.44198489114158224
    },
    {
      "step": 119,
      "optim_step": 15,
      "loss": 3.176039695739746,
      "grad_norm": 13.05914306640625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 512.7652999944985,
      "epsilon_spent": 0.4441855326900365,
      "total_epsilon": 0.4441855326900365
    },
    {
      "step": 127,
      "optim_step": 16,
      "loss": 1.9179949760437012,
      "grad_norm": 3.1141035556793213,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 663.4104999975534,
      "epsilon_spent": 0.4463861742384908,
      "total_epsilon": 0.4463861742384908
    },
    {
      "step": 135,
      "optim_step": 17,
      "loss": 3.9475677013397217,
      "grad_norm": 19.966888427734375,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 683.0790999956662,
      "epsilon_spent": 0.4485868157869451,
      "total_epsilon": 0.4485868157869451
    },
    {
      "step": 143,
      "optim_step": 18,
      "loss": 3.9124302864074707,
      "grad_norm": 17.763235092163086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 586.9626000057906,
      "epsilon_spent": 0.45044065733848637,
      "total_epsilon": 0.45044065733848637
    },
    {
      "step": 151,
      "optim_step": 19,
      "loss": 3.302213668823242,
      "grad_norm": 15.205304145812988,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 625.5357999907574,
      "epsilon_spent": 0.45177599125447176,
      "total_epsilon": 0.45177599125447176
    },
    {
      "step": 159,
      "optim_step": 20,
      "loss": 5.507114887237549,
      "grad_norm": 22.529340744018555,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 644.4779000012204,
      "epsilon_spent": 0.45311132517045716,
      "total_epsilon": 0.45311132517045716
    },
    {
      "step": 167,
      "optim_step": 21,
      "loss": 2.3942949771881104,
      "grad_norm": 6.278347969055176,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.589999993681,
      "epsilon_spent": 0.45444665908644255,
      "total_epsilon": 0.45444665908644255
    },
    {
      "step": 175,
      "optim_step": 22,
      "loss": 2.701237916946411,
      "grad_norm": 4.5829596519470215,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 609.7413999959826,
      "epsilon_spent": 0.45578199300242794,
      "total_epsilon": 0.45578199300242794
    },
    {
      "step": 183,
      "optim_step": 23,
      "loss": 4.251637935638428,
      "grad_norm": 13.743067741394043,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 596.7452000040794,
      "epsilon_spent": 0.45711732691841334,
      "total_epsilon": 0.45711732691841334
    },
    {
      "step": 191,
      "optim_step": 24,
      "loss": 3.9476239681243896,
      "grad_norm": 16.214515686035156,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 579.9220000044443,
      "epsilon_spent": 0.4584526608343988,
      "total_epsilon": 0.4584526608343988
    },
    {
      "step": 199,
      "optim_step": 25,
      "loss": 1.526991605758667,
      "grad_norm": 1.4915835857391357,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 808.5709000006318,
      "epsilon_spent": 0.4597879947503842,
      "total_epsilon": 0.4597879947503842
    },
    {
      "step": 207,
      "optim_step": 26,
      "loss": 4.003340721130371,
      "grad_norm": 18.824203491210938,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 786.8477000010898,
      "epsilon_spent": 0.46112332866636957,
      "total_epsilon": 0.46112332866636957
    },
    {
      "step": 215,
      "optim_step": 27,
      "loss": 3.3721210956573486,
      "grad_norm": 18.06990623474121,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 688.1407000037143,
      "epsilon_spent": 0.46245866258235496,
      "total_epsilon": 0.46245866258235496
    },
    {
      "step": 223,
      "optim_step": 28,
      "loss": 3.516099452972412,
      "grad_norm": 18.039186477661133,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 872.0417999866186,
      "epsilon_spent": 0.46379399649834036,
      "total_epsilon": 0.46379399649834036
    },
    {
      "step": 231,
      "optim_step": 29,
      "loss": 3.724719524383545,
      "grad_norm": 18.61090850830078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 757.3850999906426,
      "epsilon_spent": 0.46512933041432575,
      "total_epsilon": 0.46512933041432575
    },
    {
      "step": 239,
      "optim_step": 30,
      "loss": 3.76904296875,
      "grad_norm": 17.097463607788086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 677.9703000065638,
      "epsilon_spent": 0.46646466433031114,
      "total_epsilon": 0.46646466433031114
    },
    {
      "step": 247,
      "optim_step": 31,
      "loss": 1.7851476669311523,
      "grad_norm": 7.066290855407715,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 653.3201999991434,
      "epsilon_spent": 0.4677999982462966,
      "total_epsilon": 0.4677999982462966
    },
    {
      "step": 255,
      "optim_step": 32,
      "loss": 3.9087488651275635,
      "grad_norm": 13.79598331451416,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 579.9470000056317,
      "epsilon_spent": 0.46872909039036437,
      "total_epsilon": 0.46872909039036437
    },
    {
      "step": 263,
      "optim_step": 33,
      "loss": 1.5379395484924316,
      "grad_norm": 1.419498324394226,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 889.8535999906017,
      "epsilon_spent": 0.4695392236658202,
      "total_epsilon": 0.4695392236658202
    },
    {
      "step": 271,
      "optim_step": 34,
      "loss": 1.6341766119003296,
      "grad_norm": 1.4732491970062256,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 895.4114999942249,
      "epsilon_spent": 0.470349356941276,
      "total_epsilon": 0.470349356941276
    },
    {
      "step": 279,
      "optim_step": 35,
      "loss": 3.563093900680542,
      "grad_norm": 18.05703353881836,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 533.9558999985456,
      "epsilon_spent": 0.4711594902167318,
      "total_epsilon": 0.4711594902167318
    },
    {
      "step": 287,
      "optim_step": 36,
      "loss": 3.7768638134002686,
      "grad_norm": 17.262248992919922,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 549.1176999930758,
      "epsilon_spent": 0.47196962349218763,
      "total_epsilon": 0.47196962349218763
    },
    {
      "step": 295,
      "optim_step": 37,
      "loss": 3.828840732574463,
      "grad_norm": 17.389101028442383,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 612.4216000025626,
      "epsilon_spent": 0.4727797567676435,
      "total_epsilon": 0.4727797567676435
    },
    {
      "step": 303,
      "optim_step": 38,
      "loss": 3.0050337314605713,
      "grad_norm": 15.536409378051758,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 668.1773999880534,
      "epsilon_spent": 0.4735898900430993,
      "total_epsilon": 0.4735898900430993
    },
    {
      "step": 311,
      "optim_step": 39,
      "loss": 4.0896148681640625,
      "grad_norm": 11.731314659118652,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 493.71359999349806,
      "epsilon_spent": 0.47440002331855513,
      "total_epsilon": 0.47440002331855513
    },
    {
      "step": 319,
      "optim_step": 40,
      "loss": 4.533756256103516,
      "grad_norm": 13.531586647033691,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 476.1092999979155,
      "epsilon_spent": 0.47521015659401095,
      "total_epsilon": 0.47521015659401095
    },
    {
      "step": 327,
      "optim_step": 41,
      "loss": 4.153301239013672,
      "grad_norm": 15.0474853515625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 485.43090000748634,
      "epsilon_spent": 0.47602028986946676,
      "total_epsilon": 0.47602028986946676
    },
    {
      "step": 335,
      "optim_step": 42,
      "loss": 3.8382999897003174,
      "grad_norm": 19.833948135375977,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 538.5829000006197,
      "epsilon_spent": 0.4768304231449226,
      "total_epsilon": 0.4768304231449226
    },
    {
      "step": 343,
      "optim_step": 43,
      "loss": 3.403510570526123,
      "grad_norm": 15.54918384552002,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 482.530900000711,
      "epsilon_spent": 0.4776405564203784,
      "total_epsilon": 0.4776405564203784
    },
    {
      "step": 351,
      "optim_step": 44,
      "loss": 3.8704569339752197,
      "grad_norm": 12.582596778869629,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 653.9680999994744,
      "epsilon_spent": 0.4784506896958342,
      "total_epsilon": 0.4784506896958342
    },
    {
      "step": 359,
      "optim_step": 45,
      "loss": 5.3377485275268555,
      "grad_norm": 19.325258255004883,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 544.7285999980522,
      "epsilon_spent": 0.47926082297129,
      "total_epsilon": 0.47926082297129
    },
    {
      "step": 367,
      "optim_step": 46,
      "loss": 4.637975215911865,
      "grad_norm": 19.72010612487793,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 572.9283999971813,
      "epsilon_spent": 0.4800709562467459,
      "total_epsilon": 0.4800709562467459
    },
    {
      "step": 375,
      "optim_step": 47,
      "loss": 3.560959577560425,
      "grad_norm": 18.47972869873047,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 651.2853000022005,
      "epsilon_spent": 0.4808810895222017,
      "total_epsilon": 0.4808810895222017
    },
    {
      "step": 383,
      "optim_step": 48,
      "loss": 3.893549919128418,
      "grad_norm": 20.286638259887695,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 654.6666000067489,
      "epsilon_spent": 0.4816912227976575,
      "total_epsilon": 0.4816912227976575
    },
    {
      "step": 391,
      "optim_step": 49,
      "loss": 4.384596824645996,
      "grad_norm": 12.180981636047363,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 725.2278000087244,
      "epsilon_spent": 0.48250135607311334,
      "total_epsilon": 0.48250135607311334
    },
    {
      "step": 399,
      "optim_step": 50,
      "loss": 5.492593765258789,
      "grad_norm": 19.359291076660156,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 899.2933999979869,
      "epsilon_spent": 0.48331148934856916,
      "total_epsilon": 0.48331148934856916
    },
    {
      "step": 407,
      "optim_step": 51,
      "loss": 3.7277603149414062,
      "grad_norm": 17.288461685180664,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 517.8522000060184,
      "epsilon_spent": 0.48412162262402497,
      "total_epsilon": 0.48412162262402497
    },
    {
      "step": 415,
      "optim_step": 52,
      "loss": 3.4285383224487305,
      "grad_norm": 17.246612548828125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 580.1238999993075,
      "epsilon_spent": 0.4849317558994808,
      "total_epsilon": 0.4849317558994808
    },
    {
      "step": 423,
      "optim_step": 53,
      "loss": 3.342592477798462,
      "grad_norm": 10.979018211364746,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 586.584299991955,
      "epsilon_spent": 0.48574188917493666,
      "total_epsilon": 0.48574188917493666
    },
    {
      "step": 431,
      "optim_step": 54,
      "loss": 2.9449737071990967,
      "grad_norm": 7.505541801452637,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 596.7876999930013,
      "epsilon_spent": 0.4865520224503925,
      "total_epsilon": 0.4865520224503925
    },
    {
      "step": 439,
      "optim_step": 55,
      "loss": 3.70587420463562,
      "grad_norm": 17.823062896728516,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 573.441799991997,
      "epsilon_spent": 0.4873621557258483,
      "total_epsilon": 0.4873621557258483
    },
    {
      "step": 447,
      "optim_step": 56,
      "loss": 2.836758852005005,
      "grad_norm": 3.579702138900757,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 549.9856999958865,
      "epsilon_spent": 0.4880381370534979,
      "total_epsilon": 0.4880381370534979
    },
    {
      "step": 455,
      "optim_step": 57,
      "loss": 3.9544503688812256,
      "grad_norm": 17.6135311126709,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 570.4387000005227,
      "epsilon_spent": 0.4885295855973316,
      "total_epsilon": 0.4885295855973316
    },
    {
      "step": 463,
      "optim_step": 58,
      "loss": 3.3767082691192627,
      "grad_norm": 16.151084899902344,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 609.3184000055771,
      "epsilon_spent": 0.4890210341411654,
      "total_epsilon": 0.4890210341411654
    },
    {
      "step": 471,
      "optim_step": 59,
      "loss": 4.030681610107422,
      "grad_norm": 14.482301712036133,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 630.3220999980113,
      "epsilon_spent": 0.4895124826849991,
      "total_epsilon": 0.4895124826849991
    },
    {
      "step": 479,
      "optim_step": 60,
      "loss": 4.570057392120361,
      "grad_norm": 16.809568405151367,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 711.0900999978185,
      "epsilon_spent": 0.4900039312288328,
      "total_epsilon": 0.4900039312288328
    },
    {
      "step": 487,
      "optim_step": 61,
      "loss": 2.924203395843506,
      "grad_norm": 12.237037658691406,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 729.3054000037955,
      "epsilon_spent": 0.49049537977266655,
      "total_epsilon": 0.49049537977266655
    },
    {
      "step": 495,
      "optim_step": 62,
      "loss": 4.8529767990112305,
      "grad_norm": 19.028444290161133,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 604.8310000041965,
      "epsilon_spent": 0.49098682831650026,
      "total_epsilon": 0.49098682831650026
    },
    {
      "step": 503,
      "optim_step": 63,
      "loss": 3.722618341445923,
      "grad_norm": 18.07379150390625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 634.8001000005752,
      "epsilon_spent": 0.491478276860334,
      "total_epsilon": 0.491478276860334
    },
    {
      "step": 511,
      "optim_step": 64,
      "loss": 3.82151460647583,
      "grad_norm": 17.74492645263672,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 544.3739999900572,
      "epsilon_spent": 0.4919697254041677,
      "total_epsilon": 0.4919697254041677
    },
    {
      "step": 519,
      "optim_step": 65,
      "loss": 3.136854887008667,
      "grad_norm": 16.935598373413086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 699.4103999895742,
      "epsilon_spent": 0.49246117394800143,
      "total_epsilon": 0.49246117394800143
    },
    {
      "step": 527,
      "optim_step": 66,
      "loss": 3.7375450134277344,
      "grad_norm": 11.527604103088379,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 629.6978000027593,
      "epsilon_spent": 0.4929526224918352,
      "total_epsilon": 0.4929526224918352
    },
    {
      "step": 535,
      "optim_step": 67,
      "loss": 1.5807520151138306,
      "grad_norm": 1.6010276079177856,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 583.2669000083115,
      "epsilon_spent": 0.4934440710356689,
      "total_epsilon": 0.4934440710356689
    },
    {
      "step": 543,
      "optim_step": 68,
      "loss": 3.243074655532837,
      "grad_norm": 16.523658752441406,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 608.4601000038674,
      "epsilon_spent": 0.49393551957950266,
      "total_epsilon": 0.49393551957950266
    },
    {
      "step": 551,
      "optim_step": 69,
      "loss": 1.4037190675735474,
      "grad_norm": 1.1899834871292114,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 682.3877999995602,
      "epsilon_spent": 0.49442696812333636,
      "total_epsilon": 0.49442696812333636
    },
    {
      "step": 559,
      "optim_step": 70,
      "loss": 4.948319911956787,
      "grad_norm": 15.918119430541992,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 657.4553999962518,
      "epsilon_spent": 0.49491841666717007,
      "total_epsilon": 0.49491841666717007
    },
    {
      "step": 567,
      "optim_step": 71,
      "loss": 3.5458731651306152,
      "grad_norm": 19.750783920288086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 693.1322000018554,
      "epsilon_spent": 0.49540986521100383,
      "total_epsilon": 0.49540986521100383
    },
    {
      "step": 575,
      "optim_step": 72,
      "loss": 4.113914489746094,
      "grad_norm": 18.134828567504883,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 626.2741000100505,
      "epsilon_spent": 0.49590131375483754,
      "total_epsilon": 0.49590131375483754
    },
    {
      "step": 583,
      "optim_step": 73,
      "loss": 4.86796236038208,
      "grad_norm": 19.749961853027344,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 636.7664999997942,
      "epsilon_spent": 0.49639276229867124,
      "total_epsilon": 0.49639276229867124
    },
    {
      "step": 591,
      "optim_step": 74,
      "loss": 3.87752103805542,
      "grad_norm": 15.720251083374023,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 534.9783999990905,
      "epsilon_spent": 0.496884210842505,
      "total_epsilon": 0.496884210842505
    },
    {
      "step": 599,
      "optim_step": 75,
      "loss": 3.948899030685425,
      "grad_norm": 15.667061805725098,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 532.2266000002855,
      "epsilon_spent": 0.4973756593863387,
      "total_epsilon": 0.4973756593863387
    },
    {
      "step": 607,
      "optim_step": 76,
      "loss": 4.056595802307129,
      "grad_norm": 19.052011489868164,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 563.0988000048092,
      "epsilon_spent": 0.4978671079301724,
      "total_epsilon": 0.4978671079301724
    },
    {
      "step": 615,
      "optim_step": 77,
      "loss": 1.7346768379211426,
      "grad_norm": 1.5356659889221191,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 490.5469999939669,
      "epsilon_spent": 0.4983585564740062,
      "total_epsilon": 0.4983585564740062
    },
    {
      "step": 623,
      "optim_step": 78,
      "loss": 4.652549743652344,
      "grad_norm": 14.15083122253418,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 452.29770000150893,
      "epsilon_spent": 0.4988500050178399,
      "total_epsilon": 0.4988500050178399
    },
    {
      "step": 631,
      "optim_step": 79,
      "loss": 3.6198036670684814,
      "grad_norm": 16.50603675842285,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 473.6889999912819,
      "epsilon_spent": 0.49934145356167364,
      "total_epsilon": 0.49934145356167364
    },
    {
      "step": 639,
      "optim_step": 80,
      "loss": 1.7518188953399658,
      "grad_norm": 4.3888678550720215,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 465.9959999989951,
      "epsilon_spent": 0.49983290210550735,
      "total_epsilon": 0.49983290210550735
    },
    {
      "step": 647,
      "optim_step": 81,
      "loss": 3.9119927883148193,
      "grad_norm": 12.271126747131348,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 604.1851999907522,
      "epsilon_spent": 0.5003243506493411,
      "total_epsilon": 0.5003243506493411
    },
    {
      "step": 655,
      "optim_step": 82,
      "loss": 3.8758604526519775,
      "grad_norm": 19.720378875732422,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 585.0856000033673,
      "epsilon_spent": 0.5008157991931748,
      "total_epsilon": 0.5008157991931748
    },
    {
      "step": 663,
      "optim_step": 83,
      "loss": 4.3805928230285645,
      "grad_norm": 13.33839225769043,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 586.0328999988269,
      "epsilon_spent": 0.5013072477370085,
      "total_epsilon": 0.5013072477370085
    },
    {
      "step": 671,
      "optim_step": 84,
      "loss": 3.3630897998809814,
      "grad_norm": 16.077112197875977,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 664.9185999995098,
      "epsilon_spent": 0.5017986962808423,
      "total_epsilon": 0.5017986962808423
    },
    {
      "step": 679,
      "optim_step": 85,
      "loss": 3.1653800010681152,
      "grad_norm": 15.359216690063477,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 755.3460999915842,
      "epsilon_spent": 0.5022901448246759,
      "total_epsilon": 0.5022901448246759
    },
    {
      "step": 687,
      "optim_step": 86,
      "loss": 1.824852466583252,
      "grad_norm": 1.2275640964508057,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 663.3807000034722,
      "epsilon_spent": 0.5027815933685097,
      "total_epsilon": 0.5027815933685097
    },
    {
      "step": 695,
      "optim_step": 87,
      "loss": 3.355867862701416,
      "grad_norm": 16.825714111328125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 537.5902999949176,
      "epsilon_spent": 0.5032730419123435,
      "total_epsilon": 0.5032730419123435
    },
    {
      "step": 703,
      "optim_step": 88,
      "loss": 1.8452816009521484,
      "grad_norm": 7.132450103759766,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 595.8324999955948,
      "epsilon_spent": 0.5037644904561771,
      "total_epsilon": 0.5037644904561771
    },
    {
      "step": 711,
      "optim_step": 89,
      "loss": 3.4164552688598633,
      "grad_norm": 15.556777954101562,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 709.1282999899704,
      "epsilon_spent": 0.5042559390000109,
      "total_epsilon": 0.5042559390000109
    },
    {
      "step": 719,
      "optim_step": 90,
      "loss": 3.344697952270508,
      "grad_norm": 17.41105079650879,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 554.332899992005,
      "epsilon_spent": 0.5047473875438446,
      "total_epsilon": 0.5047473875438446
    },
    {
      "step": 727,
      "optim_step": 91,
      "loss": 4.282175540924072,
      "grad_norm": 19.038158416748047,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 593.308600000455,
      "epsilon_spent": 0.5052388360876784,
      "total_epsilon": 0.5052388360876784
    },
    {
      "step": 735,
      "optim_step": 92,
      "loss": 5.227547645568848,
      "grad_norm": 19.824323654174805,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 520.4469000018435,
      "epsilon_spent": 0.505730284631512,
      "total_epsilon": 0.505730284631512
    },
    {
      "step": 743,
      "optim_step": 93,
      "loss": 5.0294599533081055,
      "grad_norm": 19.45465087890625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 642.4818999948911,
      "epsilon_spent": 0.5062217331753458,
      "total_epsilon": 0.5062217331753458
    },
    {
      "step": 751,
      "optim_step": 94,
      "loss": 2.399467945098877,
      "grad_norm": 1.1954116821289062,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 588.4159999986878,
      "epsilon_spent": 0.5067131817191796,
      "total_epsilon": 0.5067131817191796
    },
    {
      "step": 759,
      "optim_step": 95,
      "loss": 5.121423721313477,
      "grad_norm": 20.441390991210938,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 636.650299988105,
      "epsilon_spent": 0.5072046302630132,
      "total_epsilon": 0.5072046302630132
    },
    {
      "step": 767,
      "optim_step": 96,
      "loss": 3.5959432125091553,
      "grad_norm": 17.632831573486328,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 695.8072999987053,
      "epsilon_spent": 0.507696078806847,
      "total_epsilon": 0.507696078806847
    },
    {
      "step": 775,
      "optim_step": 97,
      "loss": 2.797023296356201,
      "grad_norm": 1.2940378189086914,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 682.7803999913158,
      "epsilon_spent": 0.5081875273506807,
      "total_epsilon": 0.5081875273506807
    },
    {
      "step": 783,
      "optim_step": 98,
      "loss": 3.3349483013153076,
      "grad_norm": 9.361915588378906,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 606.1278999986826,
      "epsilon_spent": 0.5086789758945144,
      "total_epsilon": 0.5086789758945144
    },
    {
      "step": 791,
      "optim_step": 99,
      "loss": 4.152990818023682,
      "grad_norm": 19.088254928588867,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 875.45439999667,
      "epsilon_spent": 0.5091704244383481,
      "total_epsilon": 0.5091704244383481
    },
    {
      "step": 799,
      "optim_step": 100,
      "loss": 2.1411256790161133,
      "grad_norm": 1.3891067504882812,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 712.9386000015074,
      "epsilon_spent": 0.5095159268233795,
      "total_epsilon": 0.5095159268233795
    },
    {
      "step": 807,
      "optim_step": 101,
      "loss": 4.110433101654053,
      "grad_norm": 12.510217666625977,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 457.5788000074681,
      "epsilon_spent": 0.5098140338145425,
      "total_epsilon": 0.5098140338145425
    },
    {
      "step": 815,
      "optim_step": 102,
      "loss": 3.3083653450012207,
      "grad_norm": 17.696670532226562,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 648.2109000062337,
      "epsilon_spent": 0.5101121408057053,
      "total_epsilon": 0.5101121408057053
    },
    {
      "step": 823,
      "optim_step": 103,
      "loss": 4.518402576446533,
      "grad_norm": 14.35999870300293,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 600.959999996121,
      "epsilon_spent": 0.5104102477968682,
      "total_epsilon": 0.5104102477968682
    },
    {
      "step": 831,
      "optim_step": 104,
      "loss": 4.117997169494629,
      "grad_norm": 18.761362075805664,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 485.50900000554975,
      "epsilon_spent": 0.510708354788031,
      "total_epsilon": 0.510708354788031
    },
    {
      "step": 839,
      "optim_step": 105,
      "loss": 3.849019765853882,
      "grad_norm": 19.23736000061035,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 524.5105000067269,
      "epsilon_spent": 0.511006461779194,
      "total_epsilon": 0.511006461779194
    },
    {
      "step": 847,
      "optim_step": 106,
      "loss": 3.2212085723876953,
      "grad_norm": 15.564586639404297,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 508.2038999971701,
      "epsilon_spent": 0.5113045687703568,
      "total_epsilon": 0.5113045687703568
    },
    {
      "step": 855,
      "optim_step": 107,
      "loss": 3.3162271976470947,
      "grad_norm": 16.186735153198242,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 578.2987999991747,
      "epsilon_spent": 0.5116026757615196,
      "total_epsilon": 0.5116026757615196
    },
    {
      "step": 863,
      "optim_step": 108,
      "loss": 4.637878894805908,
      "grad_norm": 18.160037994384766,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 611.1598999996204,
      "epsilon_spent": 0.5119007827526825,
      "total_epsilon": 0.5119007827526825
    },
    {
      "step": 871,
      "optim_step": 109,
      "loss": 4.967270374298096,
      "grad_norm": 16.355937957763672,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 603.3369000069797,
      "epsilon_spent": 0.5121988897438454,
      "total_epsilon": 0.5121988897438454
    },
    {
      "step": 879,
      "optim_step": 110,
      "loss": 3.3465888500213623,
      "grad_norm": 15.59841251373291,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 625.6969999958528,
      "epsilon_spent": 0.5124969967350083,
      "total_epsilon": 0.5124969967350083
    },
    {
      "step": 887,
      "optim_step": 111,
      "loss": 4.0016374588012695,
      "grad_norm": 14.5429105758667,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 690.095800004201,
      "epsilon_spent": 0.5127951037261711,
      "total_epsilon": 0.5127951037261711
    },
    {
      "step": 895,
      "optim_step": 112,
      "loss": 4.123829364776611,
      "grad_norm": 20.61505699157715,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 624.9733000004198,
      "epsilon_spent": 0.5130932107173339,
      "total_epsilon": 0.5130932107173339
    },
    {
      "step": 903,
      "optim_step": 113,
      "loss": 4.177377223968506,
      "grad_norm": 19.515409469604492,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 610.3406000038376,
      "epsilon_spent": 0.5133913177084969,
      "total_epsilon": 0.5133913177084969
    },
    {
      "step": 911,
      "optim_step": 114,
      "loss": 3.171767473220825,
      "grad_norm": 16.460468292236328,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 639.8970000009285,
      "epsilon_spent": 0.5136894246996597,
      "total_epsilon": 0.5136894246996597
    },
    {
      "step": 919,
      "optim_step": 115,
      "loss": 3.5433738231658936,
      "grad_norm": 18.314783096313477,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 579.903199992259,
      "epsilon_spent": 0.5139875316908226,
      "total_epsilon": 0.5139875316908226
    },
    {
      "step": 927,
      "optim_step": 116,
      "loss": 3.0422539710998535,
      "grad_norm": 9.1912202835083,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 649.2412999941735,
      "epsilon_spent": 0.5142856386819854,
      "total_epsilon": 0.5142856386819854
    },
    {
      "step": 935,
      "optim_step": 117,
      "loss": 4.189537525177002,
      "grad_norm": 14.720014572143555,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 603.3396999991965,
      "epsilon_spent": 0.5145837456731484,
      "total_epsilon": 0.5145837456731484
    },
    {
      "step": 943,
      "optim_step": 118,
      "loss": 3.446343421936035,
      "grad_norm": 16.6234073638916,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 556.2256999983219,
      "epsilon_spent": 0.5148818526643112,
      "total_epsilon": 0.5148818526643112
    },
    {
      "step": 951,
      "optim_step": 119,
      "loss": 5.1547651290893555,
      "grad_norm": 16.193519592285156,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 645.586300001014,
      "epsilon_spent": 0.515179959655474,
      "total_epsilon": 0.515179959655474
    },
    {
      "step": 959,
      "optim_step": 120,
      "loss": 3.7027976512908936,
      "grad_norm": 17.808286666870117,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 506.67329999851063,
      "epsilon_spent": 0.5154780666466369,
      "total_epsilon": 0.5154780666466369
    },
    {
      "step": 967,
      "optim_step": 121,
      "loss": 3.936030149459839,
      "grad_norm": 19.39238929748535,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 622.0908999966923,
      "epsilon_spent": 0.5157761736377998,
      "total_epsilon": 0.5157761736377998
    },
    {
      "step": 975,
      "optim_step": 122,
      "loss": 4.138177871704102,
      "grad_norm": 15.067607879638672,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 644.9826000025496,
      "epsilon_spent": 0.5160742806289627,
      "total_epsilon": 0.5160742806289627
    },
    {
      "step": 983,
      "optim_step": 123,
      "loss": 3.124575138092041,
      "grad_norm": 8.702692031860352,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 682.7390000107698,
      "epsilon_spent": 0.5163723876201255,
      "total_epsilon": 0.5163723876201255
    },
    {
      "step": 991,
      "optim_step": 124,
      "loss": 2.3560492992401123,
      "grad_norm": 2.517338752746582,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 602.8248000075109,
      "epsilon_spent": 0.5166704946112883,
      "total_epsilon": 0.5166704946112883
    },
    {
      "step": 999,
      "optim_step": 125,
      "loss": 3.31396484375,
      "grad_norm": 17.209867477416992,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 526.1965999961831,
      "epsilon_spent": 0.5169686016024513,
      "total_epsilon": 0.5169686016024513
    },
    {
      "step": 1007,
      "optim_step": 126,
      "loss": 3.151421546936035,
      "grad_norm": 17.29660415649414,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 722.2142999962671,
      "epsilon_spent": 0.5172667085936141,
      "total_epsilon": 0.5172667085936141
    },
    {
      "step": 1015,
      "optim_step": 127,
      "loss": 4.5637640953063965,
      "grad_norm": 15.102530479431152,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 657.9846999957226,
      "epsilon_spent": 0.517564815584777,
      "total_epsilon": 0.517564815584777
    },
    {
      "step": 1023,
      "optim_step": 128,
      "loss": 3.938737154006958,
      "grad_norm": 12.32478141784668,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 632.458799998858,
      "epsilon_spent": 0.5178629225759398,
      "total_epsilon": 0.5178629225759398
    },
    {
      "step": 1031,
      "optim_step": 129,
      "loss": 3.489359140396118,
      "grad_norm": 17.597591400146484,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 582.3283000063384,
      "epsilon_spent": 0.5181610295671027,
      "total_epsilon": 0.5181610295671027
    },
    {
      "step": 1039,
      "optim_step": 130,
      "loss": 5.705585479736328,
      "grad_norm": 19.729108810424805,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 618.4510000020964,
      "epsilon_spent": 0.5184591365582656,
      "total_epsilon": 0.5184591365582656
    },
    {
      "step": 1047,
      "optim_step": 131,
      "loss": 1.7948439121246338,
      "grad_norm": 6.876084327697754,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 598.7791999941692,
      "epsilon_spent": 0.5187572435494284,
      "total_epsilon": 0.5187572435494284
    },
    {
      "step": 1055,
      "optim_step": 132,
      "loss": 3.986102819442749,
      "grad_norm": 13.649540901184082,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 591.8201999884332,
      "epsilon_spent": 0.5190553505405913,
      "total_epsilon": 0.5190553505405913
    },
    {
      "step": 1063,
      "optim_step": 133,
      "loss": 3.6596341133117676,
      "grad_norm": 16.84293556213379,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 684.2803000035929,
      "epsilon_spent": 0.5193534575317542,
      "total_epsilon": 0.5193534575317542
    },
    {
      "step": 1071,
      "optim_step": 134,
      "loss": 4.947925090789795,
      "grad_norm": 20.4722900390625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 663.1458000047132,
      "epsilon_spent": 0.519651564522917,
      "total_epsilon": 0.519651564522917
    },
    {
      "step": 1079,
      "optim_step": 135,
      "loss": 4.66366720199585,
      "grad_norm": 15.290485382080078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 600.24839999096,
      "epsilon_spent": 0.5199496715140799,
      "total_epsilon": 0.5199496715140799
    },
    {
      "step": 1087,
      "optim_step": 136,
      "loss": 3.3677380084991455,
      "grad_norm": 17.896272659301758,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 662.2750999958953,
      "epsilon_spent": 0.5202477785052427,
      "total_epsilon": 0.5202477785052427
    },
    {
      "step": 1095,
      "optim_step": 137,
      "loss": 4.211079120635986,
      "grad_norm": 19.356645584106445,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 644.9702999962028,
      "epsilon_spent": 0.5205458854964057,
      "total_epsilon": 0.5205458854964057
    },
    {
      "step": 1103,
      "optim_step": 138,
      "loss": 4.766812324523926,
      "grad_norm": 21.51532554626465,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.3788000048371,
      "epsilon_spent": 0.5208439924875685,
      "total_epsilon": 0.5208439924875685
    },
    {
      "step": 1111,
      "optim_step": 139,
      "loss": 1.8466930389404297,
      "grad_norm": 1.3548946380615234,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 718.8440999889281,
      "epsilon_spent": 0.5211420994787314,
      "total_epsilon": 0.5211420994787314
    },
    {
      "step": 1119,
      "optim_step": 140,
      "loss": 3.4394843578338623,
      "grad_norm": 11.8003511428833,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 622.665999995661,
      "epsilon_spent": 0.5214402064698942,
      "total_epsilon": 0.5214402064698942
    },
    {
      "step": 1127,
      "optim_step": 141,
      "loss": 3.3312950134277344,
      "grad_norm": 15.127038955688477,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 642.3723000043537,
      "epsilon_spent": 0.5217383134610571,
      "total_epsilon": 0.5217383134610571
    },
    {
      "step": 1135,
      "optim_step": 142,
      "loss": 4.586201190948486,
      "grad_norm": 17.633729934692383,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 655.4347000055714,
      "epsilon_spent": 0.52203642045222,
      "total_epsilon": 0.52203642045222
    },
    {
      "step": 1143,
      "optim_step": 143,
      "loss": 1.4820361137390137,
      "grad_norm": 2.9072227478027344,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 438.9300000038929,
      "epsilon_spent": 0.5223345274433828,
      "total_epsilon": 0.5223345274433828
    },
    {
      "step": 1151,
      "optim_step": 144,
      "loss": 2.630606174468994,
      "grad_norm": 7.905257701873779,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 752.9276999994181,
      "epsilon_spent": 0.5226326344345457,
      "total_epsilon": 0.5226326344345457
    },
    {
      "step": 1159,
      "optim_step": 145,
      "loss": 3.830671548843384,
      "grad_norm": 17.780656814575195,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 563.5136000055354,
      "epsilon_spent": 0.5229307414257086,
      "total_epsilon": 0.5229307414257086
    },
    {
      "step": 1167,
      "optim_step": 146,
      "loss": 3.056619167327881,
      "grad_norm": 10.279678344726562,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 658.0603000038536,
      "epsilon_spent": 0.5232288484168715,
      "total_epsilon": 0.5232288484168715
    },
    {
      "step": 1175,
      "optim_step": 147,
      "loss": 3.278965950012207,
      "grad_norm": 15.27143383026123,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 673.4954000130529,
      "epsilon_spent": 0.5235269554080343,
      "total_epsilon": 0.5235269554080343
    },
    {
      "step": 1183,
      "optim_step": 148,
      "loss": 2.885438919067383,
      "grad_norm": 13.106555938720703,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 670.5035000049975,
      "epsilon_spent": 0.5238250623991971,
      "total_epsilon": 0.5238250623991971
    },
    {
      "step": 1191,
      "optim_step": 149,
      "loss": 3.0993382930755615,
      "grad_norm": 15.272109985351562,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 622.9403999896022,
      "epsilon_spent": 0.5241231693903601,
      "total_epsilon": 0.5241231693903601
    },
    {
      "step": 1199,
      "optim_step": 150,
      "loss": 3.6237282752990723,
      "grad_norm": 17.933670043945312,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 557.6120000041556,
      "epsilon_spent": 0.5244212763815229,
      "total_epsilon": 0.5244212763815229
    },
    {
      "step": 1207,
      "optim_step": 151,
      "loss": 4.2245635986328125,
      "grad_norm": 18.237306594848633,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1239.7210000053747,
      "epsilon_spent": 0.5247193833726858,
      "total_epsilon": 0.5247193833726858
    },
    {
      "step": 1215,
      "optim_step": 152,
      "loss": 3.2567005157470703,
      "grad_norm": 16.73512840270996,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 536.0816000029445,
      "epsilon_spent": 0.5250174903638486,
      "total_epsilon": 0.5250174903638486
    },
    {
      "step": 1223,
      "optim_step": 153,
      "loss": 2.6711509227752686,
      "grad_norm": 1.1816202402114868,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 597.7344999992056,
      "epsilon_spent": 0.5253155973550115,
      "total_epsilon": 0.5253155973550115
    },
    {
      "step": 1231,
      "optim_step": 154,
      "loss": 3.0615234375,
      "grad_norm": 13.357370376586914,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 576.5179000009084,
      "epsilon_spent": 0.5256137043461744,
      "total_epsilon": 0.5256137043461744
    },
    {
      "step": 1239,
      "optim_step": 155,
      "loss": 4.462939262390137,
      "grad_norm": 13.715863227844238,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 657.5722999987192,
      "epsilon_spent": 0.5259118113373372,
      "total_epsilon": 0.5259118113373372
    },
    {
      "step": 1247,
      "optim_step": 156,
      "loss": 3.1131956577301025,
      "grad_norm": 15.367964744567871,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 646.3070000027074,
      "epsilon_spent": 0.5262099183285001,
      "total_epsilon": 0.5262099183285001
    },
    {
      "step": 1255,
      "optim_step": 157,
      "loss": 4.685422420501709,
      "grad_norm": 14.212347030639648,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 588.3957999903942,
      "epsilon_spent": 0.526508025319663,
      "total_epsilon": 0.526508025319663
    },
    {
      "step": 1263,
      "optim_step": 158,
      "loss": 3.6853127479553223,
      "grad_norm": 14.806217193603516,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 548.9761000062572,
      "epsilon_spent": 0.5268061323108258,
      "total_epsilon": 0.5268061323108258
    },
    {
      "step": 1271,
      "optim_step": 159,
      "loss": 3.2608048915863037,
      "grad_norm": 16.886215209960938,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 599.944300003699,
      "epsilon_spent": 0.5271042393019887,
      "total_epsilon": 0.5271042393019887
    },
    {
      "step": 1279,
      "optim_step": 160,
      "loss": 3.2879676818847656,
      "grad_norm": 17.87323570251465,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 562.774799996987,
      "epsilon_spent": 0.5274023462931515,
      "total_epsilon": 0.5274023462931515
    },
    {
      "step": 1287,
      "optim_step": 161,
      "loss": 3.849363327026367,
      "grad_norm": 19.96454429626465,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 590.174199998728,
      "epsilon_spent": 0.5277004532843145,
      "total_epsilon": 0.5277004532843145
    },
    {
      "step": 1295,
      "optim_step": 162,
      "loss": 3.6443493366241455,
      "grad_norm": 17.44267463684082,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 574.3936000071699,
      "epsilon_spent": 0.5279985602754773,
      "total_epsilon": 0.5279985602754773
    },
    {
      "step": 1303,
      "optim_step": 163,
      "loss": 3.3362948894500732,
      "grad_norm": 16.28853988647461,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 566.5669000009075,
      "epsilon_spent": 0.5282966672666402,
      "total_epsilon": 0.5282966672666402
    },
    {
      "step": 1311,
      "optim_step": 164,
      "loss": 3.5213077068328857,
      "grad_norm": 17.107463836669922,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 639.1546999948332,
      "epsilon_spent": 0.528594774257803,
      "total_epsilon": 0.528594774257803
    },
    {
      "step": 1319,
      "optim_step": 165,
      "loss": 3.910937786102295,
      "grad_norm": 12.703961372375488,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 2128.2690999942133,
      "epsilon_spent": 0.5288928812489659,
      "total_epsilon": 0.5288928812489659
    },
    {
      "step": 1327,
      "optim_step": 166,
      "loss": 3.2877767086029053,
      "grad_norm": 14.142480850219727,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 527.3579000058817,
      "epsilon_spent": 0.5291909882401288,
      "total_epsilon": 0.5291909882401288
    },
    {
      "step": 1335,
      "optim_step": 167,
      "loss": 5.880574703216553,
      "grad_norm": 20.255590438842773,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 587.2289999970235,
      "epsilon_spent": 0.5294890952312916,
      "total_epsilon": 0.5294890952312916
    },
    {
      "step": 1343,
      "optim_step": 168,
      "loss": 4.848026752471924,
      "grad_norm": 25.238571166992188,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 580.9906000067713,
      "epsilon_spent": 0.5297872022224545,
      "total_epsilon": 0.5297872022224545
    },
    {
      "step": 1351,
      "optim_step": 169,
      "loss": 5.491581439971924,
      "grad_norm": 22.186134338378906,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 683.8527000072645,
      "epsilon_spent": 0.5300853092136174,
      "total_epsilon": 0.5300853092136174
    },
    {
      "step": 1359,
      "optim_step": 170,
      "loss": 3.867624282836914,
      "grad_norm": 19.695302963256836,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 479.96370001055766,
      "epsilon_spent": 0.5303834162047802,
      "total_epsilon": 0.5303834162047802
    },
    {
      "step": 1367,
      "optim_step": 171,
      "loss": 5.398059844970703,
      "grad_norm": 15.942442893981934,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 692.7510999958031,
      "epsilon_spent": 0.5306815231959431,
      "total_epsilon": 0.5306815231959431
    },
    {
      "step": 1375,
      "optim_step": 172,
      "loss": 4.3401198387146,
      "grad_norm": 20.772274017333984,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 682.4550999881467,
      "epsilon_spent": 0.5309796301871059,
      "total_epsilon": 0.5309796301871059
    },
    {
      "step": 1383,
      "optim_step": 173,
      "loss": 4.904873847961426,
      "grad_norm": 21.319185256958008,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 501.57589999435004,
      "epsilon_spent": 0.5312777371782689,
      "total_epsilon": 0.5312777371782689
    },
    {
      "step": 1391,
      "optim_step": 174,
      "loss": 2.297292947769165,
      "grad_norm": 5.700541019439697,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 618.6248999874806,
      "epsilon_spent": 0.5315758441694317,
      "total_epsilon": 0.5315758441694317
    },
    {
      "step": 1399,
      "optim_step": 175,
      "loss": 2.055284261703491,
      "grad_norm": 6.314275741577148,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 587.1815999998944,
      "epsilon_spent": 0.5318739511605945,
      "total_epsilon": 0.5318739511605945
    },
    {
      "step": 1407,
      "optim_step": 176,
      "loss": 5.344812393188477,
      "grad_norm": 15.929804801940918,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 524.3810999963898,
      "epsilon_spent": 0.5321720581517574,
      "total_epsilon": 0.5321720581517574
    },
    {
      "step": 1415,
      "optim_step": 177,
      "loss": 3.4760446548461914,
      "grad_norm": 17.120647430419922,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 672.2806000034325,
      "epsilon_spent": 0.5324701651429203,
      "total_epsilon": 0.5324701651429203
    },
    {
      "step": 1423,
      "optim_step": 178,
      "loss": 4.231330871582031,
      "grad_norm": 17.549959182739258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 756.6507000010461,
      "epsilon_spent": 0.5327481497830253,
      "total_epsilon": 0.5327481497830253
    },
    {
      "step": 1431,
      "optim_step": 179,
      "loss": 3.170034885406494,
      "grad_norm": 14.522132873535156,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1053.0170999991242,
      "epsilon_spent": 0.5329289709799084,
      "total_epsilon": 0.5329289709799084
    },
    {
      "step": 1439,
      "optim_step": 180,
      "loss": 3.5722603797912598,
      "grad_norm": 14.357732772827148,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1331.538400001591,
      "epsilon_spent": 0.5331097921767916,
      "total_epsilon": 0.5331097921767916
    },
    {
      "step": 1447,
      "optim_step": 181,
      "loss": 4.182160377502441,
      "grad_norm": 14.202957153320312,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 554.2685999971582,
      "epsilon_spent": 0.5332906133736746,
      "total_epsilon": 0.5332906133736746
    },
    {
      "step": 1455,
      "optim_step": 182,
      "loss": 3.460622787475586,
      "grad_norm": 17.1423397064209,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1334.1314999997849,
      "epsilon_spent": 0.5334714345705577,
      "total_epsilon": 0.5334714345705577
    },
    {
      "step": 1463,
      "optim_step": 183,
      "loss": 3.8361740112304688,
      "grad_norm": 19.99236488342285,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 652.1310999960406,
      "epsilon_spent": 0.5336522557674408,
      "total_epsilon": 0.5336522557674408
    },
    {
      "step": 1471,
      "optim_step": 184,
      "loss": 3.6221842765808105,
      "grad_norm": 17.550495147705078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 732.0102999947267,
      "epsilon_spent": 0.5338330769643239,
      "total_epsilon": 0.5338330769643239
    },
    {
      "step": 1479,
      "optim_step": 185,
      "loss": 5.058401584625244,
      "grad_norm": 21.855623245239258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 561.5233999997145,
      "epsilon_spent": 0.5340138981612069,
      "total_epsilon": 0.5340138981612069
    },
    {
      "step": 1487,
      "optim_step": 186,
      "loss": 3.5594537258148193,
      "grad_norm": 19.4326229095459,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 433.26239999441896,
      "epsilon_spent": 0.53419471935809,
      "total_epsilon": 0.53419471935809
    },
    {
      "step": 1495,
      "optim_step": 187,
      "loss": 1.7959648370742798,
      "grad_norm": 6.199061393737793,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 492.9314000037266,
      "epsilon_spent": 0.5343755405549732,
      "total_epsilon": 0.5343755405549732
    },
    {
      "step": 1503,
      "optim_step": 188,
      "loss": 3.7002506256103516,
      "grad_norm": 14.752954483032227,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 761.3405000010971,
      "epsilon_spent": 0.5345563617518562,
      "total_epsilon": 0.5345563617518562
    },
    {
      "step": 1511,
      "optim_step": 189,
      "loss": 4.8500518798828125,
      "grad_norm": 20.501991271972656,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 609.8862999933772,
      "epsilon_spent": 0.5347371829487393,
      "total_epsilon": 0.5347371829487393
    },
    {
      "step": 1519,
      "optim_step": 190,
      "loss": 1.1217055320739746,
      "grad_norm": 1.253904104232788,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 636.6343999980018,
      "epsilon_spent": 0.5349180041456224,
      "total_epsilon": 0.5349180041456224
    },
    {
      "step": 1527,
      "optim_step": 191,
      "loss": 3.662891387939453,
      "grad_norm": 18.769559860229492,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 557.8761999931885,
      "epsilon_spent": 0.5350988253425054,
      "total_epsilon": 0.5350988253425054
    },
    {
      "step": 1535,
      "optim_step": 192,
      "loss": 3.6107895374298096,
      "grad_norm": 17.391000747680664,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 525.0878000078956,
      "epsilon_spent": 0.5352796465393885,
      "total_epsilon": 0.5352796465393885
    },
    {
      "step": 1543,
      "optim_step": 193,
      "loss": 1.68952476978302,
      "grad_norm": 4.695001125335693,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 523.8048000028357,
      "epsilon_spent": 0.5354604677362717,
      "total_epsilon": 0.5354604677362717
    },
    {
      "step": 1551,
      "optim_step": 194,
      "loss": 3.1182432174682617,
      "grad_norm": 14.623291969299316,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 537.2115000063786,
      "epsilon_spent": 0.5356412889331547,
      "total_epsilon": 0.5356412889331547
    },
    {
      "step": 1559,
      "optim_step": 195,
      "loss": 3.7238519191741943,
      "grad_norm": 12.586758613586426,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1125.5745999951614,
      "epsilon_spent": 0.5358221101300378,
      "total_epsilon": 0.5358221101300378
    },
    {
      "step": 1567,
      "optim_step": 196,
      "loss": 3.1709015369415283,
      "grad_norm": 16.393173217773438,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 515.783900002134,
      "epsilon_spent": 0.5360029313269209,
      "total_epsilon": 0.5360029313269209
    },
    {
      "step": 1575,
      "optim_step": 197,
      "loss": 4.700603485107422,
      "grad_norm": 17.649066925048828,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.3341000096407,
      "epsilon_spent": 0.536183752523804,
      "total_epsilon": 0.536183752523804
    },
    {
      "step": 1583,
      "optim_step": 198,
      "loss": 3.6112184524536133,
      "grad_norm": 11.501898765563965,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 562.4951000063447,
      "epsilon_spent": 0.536364573720687,
      "total_epsilon": 0.536364573720687
    },
    {
      "step": 1591,
      "optim_step": 199,
      "loss": 4.260776996612549,
      "grad_norm": 20.065155029296875,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.691400009091,
      "epsilon_spent": 0.5365453949175701,
      "total_epsilon": 0.5365453949175701
    },
    {
      "step": 1599,
      "optim_step": 200,
      "loss": 3.840423107147217,
      "grad_norm": 19.728727340698242,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 572.4329999939073,
      "epsilon_spent": 0.5367262161144533,
      "total_epsilon": 0.5367262161144533
    },
    {
      "step": 1607,
      "optim_step": 201,
      "loss": 4.889791965484619,
      "grad_norm": 15.228435516357422,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 566.254100005608,
      "epsilon_spent": 0.5369070373113363,
      "total_epsilon": 0.5369070373113363
    },
    {
      "step": 1615,
      "optim_step": 202,
      "loss": 1.6464543342590332,
      "grad_norm": 1.3577677011489868,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 574.056900004507,
      "epsilon_spent": 0.5370878585082194,
      "total_epsilon": 0.5370878585082194
    },
    {
      "step": 1623,
      "optim_step": 203,
      "loss": 3.908940315246582,
      "grad_norm": 19.363588333129883,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 561.3720999972429,
      "epsilon_spent": 0.5372686797051025,
      "total_epsilon": 0.5372686797051025
    },
    {
      "step": 1631,
      "optim_step": 204,
      "loss": 4.242952823638916,
      "grad_norm": 16.25377082824707,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 540.627599999425,
      "epsilon_spent": 0.5374495009019855,
      "total_epsilon": 0.5374495009019855
    },
    {
      "step": 1639,
      "optim_step": 205,
      "loss": 2.940556764602661,
      "grad_norm": 13.370596885681152,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 610.0318999961019,
      "epsilon_spent": 0.5376303220988686,
      "total_epsilon": 0.5376303220988686
    },
    {
      "step": 1647,
      "optim_step": 206,
      "loss": 3.4129445552825928,
      "grad_norm": 14.425176620483398,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 537.4853999965126,
      "epsilon_spent": 0.5378111432957517,
      "total_epsilon": 0.5378111432957517
    },
    {
      "step": 1655,
      "optim_step": 207,
      "loss": 3.200083017349243,
      "grad_norm": 16.528709411621094,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 540.7900999998674,
      "epsilon_spent": 0.5379919644926348,
      "total_epsilon": 0.5379919644926348
    },
    {
      "step": 1663,
      "optim_step": 208,
      "loss": 3.5518577098846436,
      "grad_norm": 18.367013931274414,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 545.9580999886384,
      "epsilon_spent": 0.5381727856895179,
      "total_epsilon": 0.5381727856895179
    },
    {
      "step": 1671,
      "optim_step": 209,
      "loss": 3.2842016220092773,
      "grad_norm": 17.404739379882812,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.7215000054566,
      "epsilon_spent": 0.538353606886401,
      "total_epsilon": 0.538353606886401
    },
    {
      "step": 1679,
      "optim_step": 210,
      "loss": 4.416532516479492,
      "grad_norm": 13.895098686218262,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 558.174699996016,
      "epsilon_spent": 0.538534428083284,
      "total_epsilon": 0.538534428083284
    },
    {
      "step": 1687,
      "optim_step": 211,
      "loss": 2.615185260772705,
      "grad_norm": 11.262290954589844,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 553.9590999978827,
      "epsilon_spent": 0.5387152492801671,
      "total_epsilon": 0.5387152492801671
    },
    {
      "step": 1695,
      "optim_step": 212,
      "loss": 3.2052392959594727,
      "grad_norm": 14.524482727050781,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 573.5521000024164,
      "epsilon_spent": 0.5388960704770502,
      "total_epsilon": 0.5388960704770502
    },
    {
      "step": 1703,
      "optim_step": 213,
      "loss": 4.2873358726501465,
      "grad_norm": 14.24068546295166,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 539.4889999879524,
      "epsilon_spent": 0.5390768916739332,
      "total_epsilon": 0.5390768916739332
    },
    {
      "step": 1711,
      "optim_step": 214,
      "loss": 4.9663801193237305,
      "grad_norm": 18.0554256439209,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1831.2880000012228,
      "epsilon_spent": 0.5392577128708164,
      "total_epsilon": 0.5392577128708164
    },
    {
      "step": 1719,
      "optim_step": 215,
      "loss": 2.5269787311553955,
      "grad_norm": 4.485597610473633,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 2190.590099999099,
      "epsilon_spent": 0.5394385340676995,
      "total_epsilon": 0.5394385340676995
    },
    {
      "step": 1727,
      "optim_step": 216,
      "loss": 3.41583514213562,
      "grad_norm": 14.202472686767578,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1570.6396000023233,
      "epsilon_spent": 0.5396193552645826,
      "total_epsilon": 0.5396193552645826
    },
    {
      "step": 1735,
      "optim_step": 217,
      "loss": 2.9348866939544678,
      "grad_norm": 8.98187255859375,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1470.7210000051418,
      "epsilon_spent": 0.5398001764614656,
      "total_epsilon": 0.5398001764614656
    },
    {
      "step": 1743,
      "optim_step": 218,
      "loss": 4.119382381439209,
      "grad_norm": 12.694595336914062,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1297.116100002313,
      "epsilon_spent": 0.5399809976583487,
      "total_epsilon": 0.5399809976583487
    },
    {
      "step": 1751,
      "optim_step": 219,
      "loss": 1.331413984298706,
      "grad_norm": 1.290019154548645,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1756.8916999880457,
      "epsilon_spent": 0.5401618188552318,
      "total_epsilon": 0.5401618188552318
    },
    {
      "step": 1759,
      "optim_step": 220,
      "loss": 4.099527359008789,
      "grad_norm": 16.277591705322266,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1767.971099994611,
      "epsilon_spent": 0.5403426400521149,
      "total_epsilon": 0.5403426400521149
    },
    {
      "step": 1767,
      "optim_step": 221,
      "loss": 3.066225528717041,
      "grad_norm": 11.685505867004395,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1663.2064000004902,
      "epsilon_spent": 0.540523461248998,
      "total_epsilon": 0.540523461248998
    },
    {
      "step": 1775,
      "optim_step": 222,
      "loss": 3.231748104095459,
      "grad_norm": 15.719069480895996,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 849.7279999864986,
      "epsilon_spent": 0.5407042824458811,
      "total_epsilon": 0.5407042824458811
    },
    {
      "step": 1783,
      "optim_step": 223,
      "loss": 3.212097644805908,
      "grad_norm": 9.551925659179688,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1692.9670999961672,
      "epsilon_spent": 0.5408851036427641,
      "total_epsilon": 0.5408851036427641
    },
    {
      "step": 1791,
      "optim_step": 224,
      "loss": 5.170687675476074,
      "grad_norm": 21.81560707092285,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 892.2114000015426,
      "epsilon_spent": 0.5410659248396472,
      "total_epsilon": 0.5410659248396472
    },
    {
      "step": 1799,
      "optim_step": 225,
      "loss": 3.695483684539795,
      "grad_norm": 18.098642349243164,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 536.4416999946116,
      "epsilon_spent": 0.5412467460365303,
      "total_epsilon": 0.5412467460365303
    },
    {
      "step": 1807,
      "optim_step": 226,
      "loss": 3.589487314224243,
      "grad_norm": 18.43030548095703,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 574.835899999016,
      "epsilon_spent": 0.5414275672334133,
      "total_epsilon": 0.5414275672334133
    },
    {
      "step": 1815,
      "optim_step": 227,
      "loss": 3.5653862953186035,
      "grad_norm": 17.299917221069336,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 726.8150000018068,
      "epsilon_spent": 0.5416083884302965,
      "total_epsilon": 0.5416083884302965
    },
    {
      "step": 1823,
      "optim_step": 228,
      "loss": 1.5674757957458496,
      "grad_norm": 1.2749758958816528,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 767.6791999983834,
      "epsilon_spent": 0.5417892096271796,
      "total_epsilon": 0.5417892096271796
    },
    {
      "step": 1831,
      "optim_step": 229,
      "loss": 3.6701719760894775,
      "grad_norm": 18.58518409729004,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 534.6914999972796,
      "epsilon_spent": 0.5419700308240627,
      "total_epsilon": 0.5419700308240627
    },
    {
      "step": 1839,
      "optim_step": 230,
      "loss": 4.0233564376831055,
      "grad_norm": 13.914411544799805,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 473.0299999937415,
      "epsilon_spent": 0.5421508520209457,
      "total_epsilon": 0.5421508520209457
    },
    {
      "step": 1847,
      "optim_step": 231,
      "loss": 3.297062635421753,
      "grad_norm": 16.570026397705078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 578.4891000075731,
      "epsilon_spent": 0.5423316732178288,
      "total_epsilon": 0.5423316732178288
    },
    {
      "step": 1855,
      "optim_step": 232,
      "loss": 4.640336513519287,
      "grad_norm": 17.465497970581055,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 522.0503000018653,
      "epsilon_spent": 0.5425124944147119,
      "total_epsilon": 0.5425124944147119
    },
    {
      "step": 1863,
      "optim_step": 233,
      "loss": 3.1888458728790283,
      "grad_norm": 15.004427909851074,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1392.5045999931172,
      "epsilon_spent": 0.542693315611595,
      "total_epsilon": 0.542693315611595
    },
    {
      "step": 1871,
      "optim_step": 234,
      "loss": 3.8428263664245605,
      "grad_norm": 13.363247871398926,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 641.5780000097584,
      "epsilon_spent": 0.5428741368084781,
      "total_epsilon": 0.5428741368084781
    },
    {
      "step": 1879,
      "optim_step": 235,
      "loss": 4.959062576293945,
      "grad_norm": 16.252721786499023,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 834.7458000062034,
      "epsilon_spent": 0.5430549580053612,
      "total_epsilon": 0.5430549580053612
    },
    {
      "step": 1887,
      "optim_step": 236,
      "loss": 4.68765115737915,
      "grad_norm": 16.983409881591797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 881.9099999964237,
      "epsilon_spent": 0.5432357792022442,
      "total_epsilon": 0.5432357792022442
    },
    {
      "step": 1895,
      "optim_step": 237,
      "loss": 1.7868441343307495,
      "grad_norm": 1.351850986480713,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 599.5552999956999,
      "epsilon_spent": 0.5434166003991273,
      "total_epsilon": 0.5434166003991273
    },
    {
      "step": 1903,
      "optim_step": 238,
      "loss": 3.392514228820801,
      "grad_norm": 17.534936904907227,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1005.8637000038289,
      "epsilon_spent": 0.5435974215960104,
      "total_epsilon": 0.5435974215960104
    },
    {
      "step": 1911,
      "optim_step": 239,
      "loss": 3.3439619541168213,
      "grad_norm": 16.210004806518555,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1029.3669999955455,
      "epsilon_spent": 0.5437782427928934,
      "total_epsilon": 0.5437782427928934
    },
    {
      "step": 1919,
      "optim_step": 240,
      "loss": 4.311334609985352,
      "grad_norm": 15.729001998901367,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1343.1852999929106,
      "epsilon_spent": 0.5439590639897766,
      "total_epsilon": 0.5439590639897766
    },
    {
      "step": 1927,
      "optim_step": 241,
      "loss": 3.4042887687683105,
      "grad_norm": 10.694504737854004,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1082.9870000015944,
      "epsilon_spent": 0.5441398851866597,
      "total_epsilon": 0.5441398851866597
    },
    {
      "step": 1935,
      "optim_step": 242,
      "loss": 4.235749244689941,
      "grad_norm": 12.202310562133789,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 890.8689999952912,
      "epsilon_spent": 0.5443207063835427,
      "total_epsilon": 0.5443207063835427
    },
    {
      "step": 1943,
      "optim_step": 243,
      "loss": 3.3173866271972656,
      "grad_norm": 15.546433448791504,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1012.1256999991601,
      "epsilon_spent": 0.5445015275804258,
      "total_epsilon": 0.5445015275804258
    },
    {
      "step": 1951,
      "optim_step": 244,
      "loss": 3.7164390087127686,
      "grad_norm": 18.206159591674805,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 822.333800009801,
      "epsilon_spent": 0.5446823487773089,
      "total_epsilon": 0.5446823487773089
    },
    {
      "step": 1959,
      "optim_step": 245,
      "loss": 2.1105475425720215,
      "grad_norm": 1.2168678045272827,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1129.6513999986928,
      "epsilon_spent": 0.5448631699741919,
      "total_epsilon": 0.5448631699741919
    },
    {
      "step": 1967,
      "optim_step": 246,
      "loss": 3.582420825958252,
      "grad_norm": 19.852649688720703,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 499.3839999951888,
      "epsilon_spent": 0.545043991171075,
      "total_epsilon": 0.545043991171075
    },
    {
      "step": 1975,
      "optim_step": 247,
      "loss": 4.655645370483398,
      "grad_norm": 15.113362312316895,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 1384.586500003934,
      "epsilon_spent": 0.5452248123679582,
      "total_epsilon": 0.5452248123679582
    },
    {
      "step": 1983,
      "optim_step": 248,
      "loss": 3.6625139713287354,
      "grad_norm": 16.23610496520996,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 620.7659999927273,
      "epsilon_spent": 0.5454056335648413,
      "total_epsilon": 0.5454056335648413
    },
    {
      "step": 1991,
      "optim_step": 249,
      "loss": 3.0194098949432373,
      "grad_norm": 12.774676322937012,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 859.8402999923564,
      "epsilon_spent": 0.5455864547617243,
      "total_epsilon": 0.5455864547617243
    },
    {
      "step": 1999,
      "optim_step": 250,
      "loss": 2.867584466934204,
      "grad_norm": 4.148684501647949,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 785.480299993651,
      "epsilon_spent": 0.5457672759586074,
      "total_epsilon": 0.5457672759586074
    }
  ]
}