{
  "adapter_name": "investment_expert",
  "model": "Qwen/Qwen2.5-1.5B",
  "rank": 32,
  "alpha": 64.0,
  "target_modules": [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj"
  ],
  "total_steps": 2000,
  "final_loss": 1.289272427558899,
  "best_loss": 1.066400408744812,
  "total_time_seconds": 1257.5,
  "dataset_size": 20000,
  "metrics": [
    {
      "step": 7,
      "optim_step": 1,
      "loss": 2.220003843307495,
      "grad_norm": 7.523568153381348,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 529.4344899999714,
      "epsilon_spent": 0.39335680174574433,
      "total_epsilon": 0.39335680174574433
    },
    {
      "step": 15,
      "optim_step": 2,
      "loss": 1.926169991493225,
      "grad_norm": 5.2213897705078125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 511.994159999972,
      "epsilon_spent": 0.41053272887830977,
      "total_epsilon": 0.41053272887830977
    },
    {
      "step": 23,
      "optim_step": 3,
      "loss": 2.6954848766326904,
      "grad_norm": 12.308065414428711,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 535.6819419999965,
      "epsilon_spent": 0.4214154095056829,
      "total_epsilon": 0.4214154095056829
    },
    {
      "step": 31,
      "optim_step": 4,
      "loss": 4.458374500274658,
      "grad_norm": 14.317968368530273,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 509.01409399995146,
      "epsilon_spent": 0.42955473606539063,
      "total_epsilon": 0.42955473606539063
    },
    {
      "step": 39,
      "optim_step": 5,
      "loss": 4.253093719482422,
      "grad_norm": 18.75990104675293,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 526.0076619999836,
      "epsilon_spent": 0.43589916296094133,
      "total_epsilon": 0.43589916296094133
    },
    {
      "step": 47,
      "optim_step": 6,
      "loss": 4.170205593109131,
      "grad_norm": 16.492572784423828,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 542.9820800000016,
      "epsilon_spent": 0.44084381366048514,
      "total_epsilon": 0.44084381366048514
    },
    {
      "step": 55,
      "optim_step": 7,
      "loss": 1.6968811750411987,
      "grad_norm": 1.3534178733825684,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 459.56051899997874,
      "epsilon_spent": 0.44578846436002895,
      "total_epsilon": 0.44578846436002895
    },
    {
      "step": 63,
      "optim_step": 8,
      "loss": 3.371351480484009,
      "grad_norm": 15.577832221984863,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 539.7346110000285,
      "epsilon_spent": 0.45042062847415776,
      "total_epsilon": 0.45042062847415776
    },
    {
      "step": 71,
      "optim_step": 9,
      "loss": 3.522784471511841,
      "grad_norm": 10.773279190063477,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 518.0010729999935,
      "epsilon_spent": 0.45342262617708384,
      "total_epsilon": 0.45342262617708384
    },
    {
      "step": 79,
      "optim_step": 10,
      "loss": 3.590240955352783,
      "grad_norm": 12.620548248291016,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 551.1126660000514,
      "epsilon_spent": 0.4564246238800099,
      "total_epsilon": 0.4564246238800099
    },
    {
      "step": 87,
      "optim_step": 11,
      "loss": 2.3192102909088135,
      "grad_norm": 5.4925665855407715,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 512.7208129999872,
      "epsilon_spent": 0.459426621582936,
      "total_epsilon": 0.459426621582936
    },
    {
      "step": 95,
      "optim_step": 12,
      "loss": 2.6230850219726562,
      "grad_norm": 10.808691024780273,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 550.1992150000206,
      "epsilon_spent": 0.4624286192858621,
      "total_epsilon": 0.4624286192858621
    },
    {
      "step": 103,
      "optim_step": 13,
      "loss": 5.280184745788574,
      "grad_norm": 23.074617385864258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 504.54591499999424,
      "epsilon_spent": 0.4654306169887881,
      "total_epsilon": 0.4654306169887881
    },
    {
      "step": 111,
      "optim_step": 14,
      "loss": 3.5349907875061035,
      "grad_norm": 18.289949417114258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 573.1443969999646,
      "epsilon_spent": 0.4683111147328261,
      "total_epsilon": 0.4683111147328261
    },
    {
      "step": 119,
      "optim_step": 15,
      "loss": 2.9643893241882324,
      "grad_norm": 15.845782279968262,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 511.88588600001594,
      "epsilon_spent": 0.4701329925297581,
      "total_epsilon": 0.4701329925297581
    },
    {
      "step": 127,
      "optim_step": 16,
      "loss": 3.5273821353912354,
      "grad_norm": 12.165332794189453,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 554.8420000000078,
      "epsilon_spent": 0.4719548703266901,
      "total_epsilon": 0.4719548703266901
    },
    {
      "step": 135,
      "optim_step": 17,
      "loss": 5.778286457061768,
      "grad_norm": 23.903589248657227,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 519.4451710000294,
      "epsilon_spent": 0.4737767481236221,
      "total_epsilon": 0.4737767481236221
    },
    {
      "step": 143,
      "optim_step": 18,
      "loss": 5.238816261291504,
      "grad_norm": 19.412006378173828,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 557.7329080000482,
      "epsilon_spent": 0.4755986259205541,
      "total_epsilon": 0.4755986259205541
    },
    {
      "step": 151,
      "optim_step": 19,
      "loss": 2.701861619949341,
      "grad_norm": 1.2100132703781128,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 500.58792300001187,
      "epsilon_spent": 0.47742050371748607,
      "total_epsilon": 0.47742050371748607
    },
    {
      "step": 159,
      "optim_step": 20,
      "loss": 4.556670188903809,
      "grad_norm": 19.350296020507812,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 538.3466060000046,
      "epsilon_spent": 0.4792423815144181,
      "total_epsilon": 0.4792423815144181
    },
    {
      "step": 167,
      "optim_step": 21,
      "loss": 3.500185966491699,
      "grad_norm": 18.181493759155273,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 571.7971700000248,
      "epsilon_spent": 0.4810642593113501,
      "total_epsilon": 0.4810642593113501
    },
    {
      "step": 175,
      "optim_step": 22,
      "loss": 3.9893038272857666,
      "grad_norm": 16.635726928710938,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 535.0000340000065,
      "epsilon_spent": 0.4828861371082821,
      "total_epsilon": 0.4828861371082821
    },
    {
      "step": 183,
      "optim_step": 23,
      "loss": 5.451103210449219,
      "grad_norm": 16.199180603027344,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 632.2196619999545,
      "epsilon_spent": 0.4847080149052141,
      "total_epsilon": 0.4847080149052141
    },
    {
      "step": 191,
      "optim_step": 24,
      "loss": 5.236648082733154,
      "grad_norm": 16.577585220336914,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 657.0626409999818,
      "epsilon_spent": 0.4865298927021461,
      "total_epsilon": 0.4865298927021461
    },
    {
      "step": 199,
      "optim_step": 25,
      "loss": 4.783437252044678,
      "grad_norm": 18.800569534301758,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 608.1689400000414,
      "epsilon_spent": 0.48815251305851826,
      "total_epsilon": 0.48815251305851826
    },
    {
      "step": 207,
      "optim_step": 26,
      "loss": 3.672239303588867,
      "grad_norm": 19.27549171447754,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 572.6980499999854,
      "epsilon_spent": 0.48925793283690666,
      "total_epsilon": 0.48925793283690666
    },
    {
      "step": 215,
      "optim_step": 27,
      "loss": 4.213356971740723,
      "grad_norm": 15.409697532653809,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 574.7817209999653,
      "epsilon_spent": 0.490363352615295,
      "total_epsilon": 0.490363352615295
    },
    {
      "step": 223,
      "optim_step": 28,
      "loss": 2.8624823093414307,
      "grad_norm": 14.44970989227295,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 585.971040000004,
      "epsilon_spent": 0.49146877239368336,
      "total_epsilon": 0.49146877239368336
    },
    {
      "step": 231,
      "optim_step": 29,
      "loss": 2.9258179664611816,
      "grad_norm": 12.896730422973633,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 581.804304000002,
      "epsilon_spent": 0.4925741921720717,
      "total_epsilon": 0.4925741921720717
    },
    {
      "step": 239,
      "optim_step": 30,
      "loss": 1.9747209548950195,
      "grad_norm": 1.5162287950515747,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 508.6499809999623,
      "epsilon_spent": 0.4936796119504601,
      "total_epsilon": 0.4936796119504601
    },
    {
      "step": 247,
      "optim_step": 31,
      "loss": 3.762753963470459,
      "grad_norm": 18.218822479248047,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 601.8596940000407,
      "epsilon_spent": 0.49478503172884847,
      "total_epsilon": 0.49478503172884847
    },
    {
      "step": 255,
      "optim_step": 32,
      "loss": 3.7298507690429688,
      "grad_norm": 15.326643943786621,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 555.0694049999834,
      "epsilon_spent": 0.4958904515072368,
      "total_epsilon": 0.4958904515072368
    },
    {
      "step": 263,
      "optim_step": 33,
      "loss": 3.1329336166381836,
      "grad_norm": 15.94370174407959,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 567.5808230000143,
      "epsilon_spent": 0.49699587128562517,
      "total_epsilon": 0.49699587128562517
    },
    {
      "step": 271,
      "optim_step": 34,
      "loss": 5.049907684326172,
      "grad_norm": 20.13536834716797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 561.8838679999953,
      "epsilon_spent": 0.4981012910640136,
      "total_epsilon": 0.4981012910640136
    },
    {
      "step": 279,
      "optim_step": 35,
      "loss": 3.489734411239624,
      "grad_norm": 15.387813568115234,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 553.6826160000032,
      "epsilon_spent": 0.4992067108424019,
      "total_epsilon": 0.4992067108424019
    },
    {
      "step": 287,
      "optim_step": 36,
      "loss": 4.324216365814209,
      "grad_norm": 17.92904281616211,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 536.1294499999758,
      "epsilon_spent": 0.5003121306207903,
      "total_epsilon": 0.5003121306207903
    },
    {
      "step": 295,
      "optim_step": 37,
      "loss": 3.5639195442199707,
      "grad_norm": 17.96083641052246,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 563.346077999995,
      "epsilon_spent": 0.5014175503991787,
      "total_epsilon": 0.5014175503991787
    },
    {
      "step": 303,
      "optim_step": 38,
      "loss": 3.0028011798858643,
      "grad_norm": 15.832033157348633,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 548.3019819999981,
      "epsilon_spent": 0.502522970177567,
      "total_epsilon": 0.502522970177567
    },
    {
      "step": 311,
      "optim_step": 39,
      "loss": 4.805521488189697,
      "grad_norm": 14.590336799621582,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 541.7191230000071,
      "epsilon_spent": 0.5036283899559554,
      "total_epsilon": 0.5036283899559554
    },
    {
      "step": 319,
      "optim_step": 40,
      "loss": 3.8606760501861572,
      "grad_norm": 16.298477172851562,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 588.266109000017,
      "epsilon_spent": 0.5047338097343438,
      "total_epsilon": 0.5047338097343438
    },
    {
      "step": 327,
      "optim_step": 41,
      "loss": 3.4429030418395996,
      "grad_norm": 18.289817810058594,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 542.7440309999838,
      "epsilon_spent": 0.5058392295127321,
      "total_epsilon": 0.5058392295127321
    },
    {
      "step": 335,
      "optim_step": 42,
      "loss": 1.7275729179382324,
      "grad_norm": 1.3558681011199951,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 476.3232199999834,
      "epsilon_spent": 0.5069446492911205,
      "total_epsilon": 0.5069446492911205
    },
    {
      "step": 343,
      "optim_step": 43,
      "loss": 4.337895393371582,
      "grad_norm": 18.891536712646484,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 551.5482499999962,
      "epsilon_spent": 0.5080500690695088,
      "total_epsilon": 0.5080500690695088
    },
    {
      "step": 351,
      "optim_step": 44,
      "loss": 3.526817560195923,
      "grad_norm": 17.412080764770508,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 531.9964799999752,
      "epsilon_spent": 0.5091554888478972,
      "total_epsilon": 0.5091554888478972
    },
    {
      "step": 359,
      "optim_step": 45,
      "loss": 4.837086200714111,
      "grad_norm": 18.70067596435547,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 574.2688059999637,
      "epsilon_spent": 0.5098829388533637,
      "total_epsilon": 0.5098829388533637
    },
    {
      "step": 367,
      "optim_step": 46,
      "loss": 1.4801805019378662,
      "grad_norm": 1.299547553062439,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 495.0592080000433,
      "epsilon_spent": 0.5105535546566141,
      "total_epsilon": 0.5105535546566141
    },
    {
      "step": 375,
      "optim_step": 47,
      "loss": 3.824272394180298,
      "grad_norm": 19.47872543334961,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 584.5714570000382,
      "epsilon_spent": 0.5112241704598646,
      "total_epsilon": 0.5112241704598646
    },
    {
      "step": 383,
      "optim_step": 48,
      "loss": 3.1489756107330322,
      "grad_norm": 14.217361450195312,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 552.2653430000446,
      "epsilon_spent": 0.511894786263115,
      "total_epsilon": 0.511894786263115
    },
    {
      "step": 391,
      "optim_step": 49,
      "loss": 2.7563636302948,
      "grad_norm": 9.572365760803223,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 520.0206509999816,
      "epsilon_spent": 0.5125654020663655,
      "total_epsilon": 0.5125654020663655
    },
    {
      "step": 399,
      "optim_step": 50,
      "loss": 5.9746317863464355,
      "grad_norm": 22.991365432739258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.074186999941,
      "epsilon_spent": 0.5132360178696159,
      "total_epsilon": 0.5132360178696159
    },
    {
      "step": 407,
      "optim_step": 51,
      "loss": 5.616596698760986,
      "grad_norm": 24.885421752929688,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 555.5257759999677,
      "epsilon_spent": 0.5139066336728664,
      "total_epsilon": 0.5139066336728664
    },
    {
      "step": 415,
      "optim_step": 52,
      "loss": 5.654480457305908,
      "grad_norm": 22.55661392211914,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 573.4842560000288,
      "epsilon_spent": 0.5145772494761169,
      "total_epsilon": 0.5145772494761169
    },
    {
      "step": 423,
      "optim_step": 53,
      "loss": 4.210243225097656,
      "grad_norm": 21.707439422607422,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 556.8465170000536,
      "epsilon_spent": 0.5152478652793674,
      "total_epsilon": 0.5152478652793674
    },
    {
      "step": 431,
      "optim_step": 54,
      "loss": 3.2081453800201416,
      "grad_norm": 14.166706085205078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 588.9719510000759,
      "epsilon_spent": 0.5159184810826178,
      "total_epsilon": 0.5159184810826178
    },
    {
      "step": 439,
      "optim_step": 55,
      "loss": 4.6518449783325195,
      "grad_norm": 18.007068634033203,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 553.4050979999847,
      "epsilon_spent": 0.5165890968858683,
      "total_epsilon": 0.5165890968858683
    },
    {
      "step": 447,
      "optim_step": 56,
      "loss": 4.690987586975098,
      "grad_norm": 14.789880752563477,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 519.4804270000759,
      "epsilon_spent": 0.5172597126891187,
      "total_epsilon": 0.5172597126891187
    },
    {
      "step": 455,
      "optim_step": 57,
      "loss": 2.9191572666168213,
      "grad_norm": 12.764885902404785,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 552.4603800000705,
      "epsilon_spent": 0.5179303284923692,
      "total_epsilon": 0.5179303284923692
    },
    {
      "step": 463,
      "optim_step": 58,
      "loss": 3.8058156967163086,
      "grad_norm": 17.332061767578125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 554.9586490000138,
      "epsilon_spent": 0.5186009442956196,
      "total_epsilon": 0.5186009442956196
    },
    {
      "step": 471,
      "optim_step": 59,
      "loss": 5.125717639923096,
      "grad_norm": 18.497526168823242,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 614.4149080000716,
      "epsilon_spent": 0.5192715600988701,
      "total_epsilon": 0.5192715600988701
    },
    {
      "step": 479,
      "optim_step": 60,
      "loss": 5.139854907989502,
      "grad_norm": 18.132728576660156,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 556.7542740000135,
      "epsilon_spent": 0.5199421759021207,
      "total_epsilon": 0.5199421759021207
    },
    {
      "step": 487,
      "optim_step": 61,
      "loss": 3.678170680999756,
      "grad_norm": 15.330698013305664,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 653.508808999959,
      "epsilon_spent": 0.5206127917053711,
      "total_epsilon": 0.5206127917053711
    },
    {
      "step": 495,
      "optim_step": 62,
      "loss": 2.948333740234375,
      "grad_norm": 1.2351937294006348,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 517.9035179999119,
      "epsilon_spent": 0.5212834075086216,
      "total_epsilon": 0.5212834075086216
    },
    {
      "step": 503,
      "optim_step": 63,
      "loss": 4.911200523376465,
      "grad_norm": 23.29621696472168,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 549.932222999928,
      "epsilon_spent": 0.521954023311872,
      "total_epsilon": 0.521954023311872
    },
    {
      "step": 511,
      "optim_step": 64,
      "loss": 3.1423587799072266,
      "grad_norm": 10.568889617919922,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.4085029999624,
      "epsilon_spent": 0.5226246391151225,
      "total_epsilon": 0.5226246391151225
    },
    {
      "step": 519,
      "optim_step": 65,
      "loss": 5.53427267074585,
      "grad_norm": 15.138401985168457,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 585.2553230000694,
      "epsilon_spent": 0.5232952549183729,
      "total_epsilon": 0.5232952549183729
    },
    {
      "step": 527,
      "optim_step": 66,
      "loss": 3.8037984371185303,
      "grad_norm": 16.93613052368164,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 577.5720010000214,
      "epsilon_spent": 0.5239658707216234,
      "total_epsilon": 0.5239658707216234
    },
    {
      "step": 535,
      "optim_step": 67,
      "loss": 2.541827440261841,
      "grad_norm": 1.3310209512710571,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 494.64953900007913,
      "epsilon_spent": 0.5246364865248738,
      "total_epsilon": 0.5246364865248738
    },
    {
      "step": 543,
      "optim_step": 68,
      "loss": 5.171706199645996,
      "grad_norm": 16.85672378540039,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 571.8448930000477,
      "epsilon_spent": 0.5253071023281244,
      "total_epsilon": 0.5253071023281244
    },
    {
      "step": 551,
      "optim_step": 69,
      "loss": 2.4902892112731934,
      "grad_norm": 1.4272335767745972,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 513.0488229999628,
      "epsilon_spent": 0.5259777181313748,
      "total_epsilon": 0.5259777181313748
    },
    {
      "step": 559,
      "optim_step": 70,
      "loss": 5.212756633758545,
      "grad_norm": 21.085744857788086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 554.2557109999962,
      "epsilon_spent": 0.5266483339346253,
      "total_epsilon": 0.5266483339346253
    },
    {
      "step": 567,
      "optim_step": 71,
      "loss": 2.199432373046875,
      "grad_norm": 5.318892478942871,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 576.5845539999646,
      "epsilon_spent": 0.5273189497378757,
      "total_epsilon": 0.5273189497378757
    },
    {
      "step": 575,
      "optim_step": 72,
      "loss": 1.3021013736724854,
      "grad_norm": 1.3143846988677979,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 514.4106229998897,
      "epsilon_spent": 0.5279895655411262,
      "total_epsilon": 0.5279895655411262
    },
    {
      "step": 583,
      "optim_step": 73,
      "loss": 3.3641281127929688,
      "grad_norm": 16.144563674926758,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 569.2919819999815,
      "epsilon_spent": 0.5286601813443766,
      "total_epsilon": 0.5286601813443766
    },
    {
      "step": 591,
      "optim_step": 74,
      "loss": 4.90839958190918,
      "grad_norm": 21.40001678466797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 534.644288000095,
      "epsilon_spent": 0.5293307971476271,
      "total_epsilon": 0.5293307971476271
    },
    {
      "step": 599,
      "optim_step": 75,
      "loss": 3.3620967864990234,
      "grad_norm": 10.226263046264648,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 564.5544889999883,
      "epsilon_spent": 0.5300014129508775,
      "total_epsilon": 0.5300014129508775
    },
    {
      "step": 607,
      "optim_step": 76,
      "loss": 3.4028804302215576,
      "grad_norm": 17.14621925354004,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 535.271267999974,
      "epsilon_spent": 0.5306720287541281,
      "total_epsilon": 0.5306720287541281
    },
    {
      "step": 615,
      "optim_step": 77,
      "loss": 4.608046531677246,
      "grad_norm": 18.47303009033203,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 610.148468000034,
      "epsilon_spent": 0.5313426445573786,
      "total_epsilon": 0.5313426445573786
    },
    {
      "step": 623,
      "optim_step": 78,
      "loss": 5.692112445831299,
      "grad_norm": 20.54561424255371,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 556.1649399999169,
      "epsilon_spent": 0.532013260360629,
      "total_epsilon": 0.532013260360629
    },
    {
      "step": 631,
      "optim_step": 79,
      "loss": 4.165256023406982,
      "grad_norm": 14.215482711791992,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 534.2575380000198,
      "epsilon_spent": 0.5326838761638795,
      "total_epsilon": 0.5326838761638795
    },
    {
      "step": 639,
      "optim_step": 80,
      "loss": 4.004893779754639,
      "grad_norm": 14.459555625915527,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 567.7432100000033,
      "epsilon_spent": 0.5331061146182469,
      "total_epsilon": 0.5331061146182469
    },
    {
      "step": 647,
      "optim_step": 81,
      "loss": 3.9755544662475586,
      "grad_norm": 17.58375358581543,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 557.4523830000544,
      "epsilon_spent": 0.533512916341752,
      "total_epsilon": 0.533512916341752
    },
    {
      "step": 655,
      "optim_step": 82,
      "loss": 3.4237735271453857,
      "grad_norm": 15.842138290405273,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 564.2164809999031,
      "epsilon_spent": 0.5339197180652571,
      "total_epsilon": 0.5339197180652571
    },
    {
      "step": 663,
      "optim_step": 83,
      "loss": 2.8860788345336914,
      "grad_norm": 8.41553020477295,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 575.762104999967,
      "epsilon_spent": 0.5343265197887622,
      "total_epsilon": 0.5343265197887622
    },
    {
      "step": 671,
      "optim_step": 84,
      "loss": 4.171776294708252,
      "grad_norm": 13.563064575195312,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.7416189999412,
      "epsilon_spent": 0.5347333215122674,
      "total_epsilon": 0.5347333215122674
    },
    {
      "step": 679,
      "optim_step": 85,
      "loss": 2.451486825942993,
      "grad_norm": 11.337482452392578,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 585.7186639999554,
      "epsilon_spent": 0.5351401232357725,
      "total_epsilon": 0.5351401232357725
    },
    {
      "step": 687,
      "optim_step": 86,
      "loss": 3.6811060905456543,
      "grad_norm": 16.688430786132812,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 569.4579480000357,
      "epsilon_spent": 0.5355469249592777,
      "total_epsilon": 0.5355469249592777
    },
    {
      "step": 695,
      "optim_step": 87,
      "loss": 4.293051719665527,
      "grad_norm": 16.016653060913086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 544.6936700000151,
      "epsilon_spent": 0.5359537266827828,
      "total_epsilon": 0.5359537266827828
    },
    {
      "step": 703,
      "optim_step": 88,
      "loss": 3.8098301887512207,
      "grad_norm": 14.395586013793945,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 565.411714999982,
      "epsilon_spent": 0.5363605284062879,
      "total_epsilon": 0.5363605284062879
    },
    {
      "step": 711,
      "optim_step": 89,
      "loss": 4.116815567016602,
      "grad_norm": 13.490981101989746,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 566.2612180000224,
      "epsilon_spent": 0.536767330129793,
      "total_epsilon": 0.536767330129793
    },
    {
      "step": 719,
      "optim_step": 90,
      "loss": 2.2359063625335693,
      "grad_norm": 11.225184440612793,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.7357819999379,
      "epsilon_spent": 0.5371741318532982,
      "total_epsilon": 0.5371741318532982
    },
    {
      "step": 727,
      "optim_step": 91,
      "loss": 3.817340135574341,
      "grad_norm": 14.456494331359863,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 587.1923050000305,
      "epsilon_spent": 0.5375809335768034,
      "total_epsilon": 0.5375809335768034
    },
    {
      "step": 735,
      "optim_step": 92,
      "loss": 4.231531620025635,
      "grad_norm": 18.2404727935791,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 540.4236470000114,
      "epsilon_spent": 0.5379877353003085,
      "total_epsilon": 0.5379877353003085
    },
    {
      "step": 743,
      "optim_step": 93,
      "loss": 3.3273370265960693,
      "grad_norm": 9.89479923248291,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 628.6751899999672,
      "epsilon_spent": 0.5383945370238136,
      "total_epsilon": 0.5383945370238136
    },
    {
      "step": 751,
      "optim_step": 94,
      "loss": 4.559751987457275,
      "grad_norm": 20.494009017944336,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 527.4267060000284,
      "epsilon_spent": 0.5388013387473187,
      "total_epsilon": 0.5388013387473187
    },
    {
      "step": 759,
      "optim_step": 95,
      "loss": 3.426175117492676,
      "grad_norm": 17.326313018798828,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 554.4859079999469,
      "epsilon_spent": 0.5392081404708239,
      "total_epsilon": 0.5392081404708239
    },
    {
      "step": 767,
      "optim_step": 96,
      "loss": 3.603233575820923,
      "grad_norm": 14.125167846679688,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 552.1798009999657,
      "epsilon_spent": 0.539614942194329,
      "total_epsilon": 0.539614942194329
    },
    {
      "step": 775,
      "optim_step": 97,
      "loss": 3.447566270828247,
      "grad_norm": 14.687521934509277,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 577.1065070000532,
      "epsilon_spent": 0.5400217439178342,
      "total_epsilon": 0.5400217439178342
    },
    {
      "step": 783,
      "optim_step": 98,
      "loss": 5.077884197235107,
      "grad_norm": 23.529037475585938,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 632.6217580000275,
      "epsilon_spent": 0.5404285456413394,
      "total_epsilon": 0.5404285456413394
    },
    {
      "step": 791,
      "optim_step": 99,
      "loss": 4.45308780670166,
      "grad_norm": 21.252037048339844,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 583.8886989999992,
      "epsilon_spent": 0.5408353473648444,
      "total_epsilon": 0.5408353473648444
    },
    {
      "step": 799,
      "optim_step": 100,
      "loss": 5.186097621917725,
      "grad_norm": 18.203399658203125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 535.6207220000897,
      "epsilon_spent": 0.5412421490883496,
      "total_epsilon": 0.5412421490883496
    },
    {
      "step": 807,
      "optim_step": 101,
      "loss": 3.3802473545074463,
      "grad_norm": 15.468963623046875,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 562.6367649999793,
      "epsilon_spent": 0.5416489508118547,
      "total_epsilon": 0.5416489508118547
    },
    {
      "step": 815,
      "optim_step": 102,
      "loss": 4.219874858856201,
      "grad_norm": 17.208698272705078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 548.584382999934,
      "epsilon_spent": 0.5420557525353599,
      "total_epsilon": 0.5420557525353599
    },
    {
      "step": 823,
      "optim_step": 103,
      "loss": 3.2300398349761963,
      "grad_norm": 15.672921180725098,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 542.6415420000694,
      "epsilon_spent": 0.542462554258865,
      "total_epsilon": 0.542462554258865
    },
    {
      "step": 831,
      "optim_step": 104,
      "loss": 4.35015344619751,
      "grad_norm": 19.034753799438477,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 609.2654029999949,
      "epsilon_spent": 0.5428693559823701,
      "total_epsilon": 0.5428693559823701
    },
    {
      "step": 839,
      "optim_step": 105,
      "loss": 4.409074783325195,
      "grad_norm": 18.16194725036621,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 553.3868270000539,
      "epsilon_spent": 0.5432761577058752,
      "total_epsilon": 0.5432761577058752
    },
    {
      "step": 847,
      "optim_step": 106,
      "loss": 1.4037522077560425,
      "grad_norm": 1.2659854888916016,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 508.26448099996924,
      "epsilon_spent": 0.5436829594293804,
      "total_epsilon": 0.5436829594293804
    },
    {
      "step": 855,
      "optim_step": 107,
      "loss": 4.745167255401611,
      "grad_norm": 23.479780197143555,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 598.5583309999356,
      "epsilon_spent": 0.5440897611528855,
      "total_epsilon": 0.5440897611528855
    },
    {
      "step": 863,
      "optim_step": 108,
      "loss": 2.6831610202789307,
      "grad_norm": 10.63450813293457,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 555.3333510000584,
      "epsilon_spent": 0.5444965628763907,
      "total_epsilon": 0.5444965628763907
    },
    {
      "step": 871,
      "optim_step": 109,
      "loss": 4.751359462738037,
      "grad_norm": 20.930330276489258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 542.4835999999686,
      "epsilon_spent": 0.5449033645998957,
      "total_epsilon": 0.5449033645998957
    },
    {
      "step": 879,
      "optim_step": 110,
      "loss": 4.06210994720459,
      "grad_norm": 17.156024932861328,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 585.7182460000558,
      "epsilon_spent": 0.5453101663234009,
      "total_epsilon": 0.5453101663234009
    },
    {
      "step": 887,
      "optim_step": 111,
      "loss": 1.745282769203186,
      "grad_norm": 1.3766114711761475,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 503.25043100008315,
      "epsilon_spent": 0.5457169680469061,
      "total_epsilon": 0.5457169680469061
    },
    {
      "step": 895,
      "optim_step": 112,
      "loss": 4.099303722381592,
      "grad_norm": 13.318414688110352,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 659.4697259999975,
      "epsilon_spent": 0.5461237697704112,
      "total_epsilon": 0.5461237697704112
    },
    {
      "step": 903,
      "optim_step": 113,
      "loss": 4.075377464294434,
      "grad_norm": 16.801715850830078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 552.5954750000892,
      "epsilon_spent": 0.5465305714939164,
      "total_epsilon": 0.5465305714939164
    },
    {
      "step": 911,
      "optim_step": 114,
      "loss": 3.6686065196990967,
      "grad_norm": 20.637617111206055,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 590.2005469999949,
      "epsilon_spent": 0.5469373732174214,
      "total_epsilon": 0.5469373732174214
    },
    {
      "step": 919,
      "optim_step": 115,
      "loss": 3.957993507385254,
      "grad_norm": 13.184028625488281,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 552.0843150000019,
      "epsilon_spent": 0.5473441749409266,
      "total_epsilon": 0.5473441749409266
    },
    {
      "step": 927,
      "optim_step": 116,
      "loss": 4.235347747802734,
      "grad_norm": 13.192554473876953,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 580.6240009999328,
      "epsilon_spent": 0.5477509766644317,
      "total_epsilon": 0.5477509766644317
    },
    {
      "step": 935,
      "optim_step": 117,
      "loss": 3.2834601402282715,
      "grad_norm": 16.527767181396484,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 554.4364879999648,
      "epsilon_spent": 0.5481577783879369,
      "total_epsilon": 0.5481577783879369
    },
    {
      "step": 943,
      "optim_step": 118,
      "loss": 4.661510467529297,
      "grad_norm": 20.36667823791504,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 553.8302200000089,
      "epsilon_spent": 0.548564580111442,
      "total_epsilon": 0.548564580111442
    },
    {
      "step": 951,
      "optim_step": 119,
      "loss": 3.093444585800171,
      "grad_norm": 14.164435386657715,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 596.009798999944,
      "epsilon_spent": 0.5489713818349472,
      "total_epsilon": 0.5489713818349472
    },
    {
      "step": 959,
      "optim_step": 120,
      "loss": 3.514310836791992,
      "grad_norm": 18.294824600219727,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 574.912444000006,
      "epsilon_spent": 0.5493781835584522,
      "total_epsilon": 0.5493781835584522
    },
    {
      "step": 967,
      "optim_step": 121,
      "loss": 3.8710291385650635,
      "grad_norm": 15.091766357421875,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 552.0429460000287,
      "epsilon_spent": 0.5497849852819574,
      "total_epsilon": 0.5497849852819574
    },
    {
      "step": 975,
      "optim_step": 122,
      "loss": 3.8010339736938477,
      "grad_norm": 19.947811126708984,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 567.9185989999951,
      "epsilon_spent": 0.5501917870054626,
      "total_epsilon": 0.5501917870054626
    },
    {
      "step": 983,
      "optim_step": 123,
      "loss": 5.02278470993042,
      "grad_norm": 16.368980407714844,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 557.4115699999993,
      "epsilon_spent": 0.5505985887289677,
      "total_epsilon": 0.5505985887289677
    },
    {
      "step": 991,
      "optim_step": 124,
      "loss": 3.8604233264923096,
      "grad_norm": 12.033036231994629,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 556.5814290000617,
      "epsilon_spent": 0.5510053904524729,
      "total_epsilon": 0.5510053904524729
    },
    {
      "step": 999,
      "optim_step": 125,
      "loss": 4.081760406494141,
      "grad_norm": 14.07785415649414,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 627.5067819999549,
      "epsilon_spent": 0.5514121921759779,
      "total_epsilon": 0.5514121921759779
    },
    {
      "step": 1007,
      "optim_step": 126,
      "loss": 3.5590763092041016,
      "grad_norm": 13.671113967895508,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 596.7379480000545,
      "epsilon_spent": 0.5518189938994831,
      "total_epsilon": 0.5518189938994831
    },
    {
      "step": 1015,
      "optim_step": 127,
      "loss": 3.6501049995422363,
      "grad_norm": 15.851083755493164,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 562.1335849999696,
      "epsilon_spent": 0.5522257956229882,
      "total_epsilon": 0.5522257956229882
    },
    {
      "step": 1023,
      "optim_step": 128,
      "loss": 4.377574443817139,
      "grad_norm": 14.475685119628906,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 554.0842450000127,
      "epsilon_spent": 0.5526325973464934,
      "total_epsilon": 0.5526325973464934
    },
    {
      "step": 1031,
      "optim_step": 129,
      "loss": 4.594951629638672,
      "grad_norm": 20.51250648498535,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 562.996855999927,
      "epsilon_spent": 0.5530393990699985,
      "total_epsilon": 0.5530393990699985
    },
    {
      "step": 1039,
      "optim_step": 130,
      "loss": 5.148182392120361,
      "grad_norm": 20.009923934936523,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 582.6278780000393,
      "epsilon_spent": 0.5534462007935037,
      "total_epsilon": 0.5534462007935037
    },
    {
      "step": 1047,
      "optim_step": 131,
      "loss": 4.8959856033325195,
      "grad_norm": 23.694095611572266,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 631.8345850000924,
      "epsilon_spent": 0.5538530025170088,
      "total_epsilon": 0.5538530025170088
    },
    {
      "step": 1055,
      "optim_step": 132,
      "loss": 4.616873741149902,
      "grad_norm": 20.912841796875,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 570.4400419999729,
      "epsilon_spent": 0.5542598042405139,
      "total_epsilon": 0.5542598042405139
    },
    {
      "step": 1063,
      "optim_step": 133,
      "loss": 3.824843645095825,
      "grad_norm": 18.099163055419922,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 557.7214759999833,
      "epsilon_spent": 0.5546666059640191,
      "total_epsilon": 0.5546666059640191
    },
    {
      "step": 1071,
      "optim_step": 134,
      "loss": 3.437251567840576,
      "grad_norm": 14.154006004333496,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 543.1937680000374,
      "epsilon_spent": 0.5550734076875242,
      "total_epsilon": 0.5550734076875242
    },
    {
      "step": 1079,
      "optim_step": 135,
      "loss": 1.7906326055526733,
      "grad_norm": 4.245668888092041,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 546.2216890000491,
      "epsilon_spent": 0.5554802094110294,
      "total_epsilon": 0.5554802094110294
    },
    {
      "step": 1087,
      "optim_step": 136,
      "loss": 4.6356940269470215,
      "grad_norm": 18.656461715698242,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 573.3590090000007,
      "epsilon_spent": 0.5558870111345344,
      "total_epsilon": 0.5558870111345344
    },
    {
      "step": 1095,
      "optim_step": 137,
      "loss": 4.908195495605469,
      "grad_norm": 19.897937774658203,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.0469390000171,
      "epsilon_spent": 0.5562938128580396,
      "total_epsilon": 0.5562938128580396
    },
    {
      "step": 1103,
      "optim_step": 138,
      "loss": 3.192293882369995,
      "grad_norm": 12.988656997680664,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 554.7027989999833,
      "epsilon_spent": 0.5567006145815447,
      "total_epsilon": 0.5567006145815447
    },
    {
      "step": 1111,
      "optim_step": 139,
      "loss": 1.473868489265442,
      "grad_norm": 1.4463154077529907,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 505.4119910000736,
      "epsilon_spent": 0.5571074163050499,
      "total_epsilon": 0.5571074163050499
    },
    {
      "step": 1119,
      "optim_step": 140,
      "loss": 2.5501346588134766,
      "grad_norm": 7.594268798828125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 544.0710950000494,
      "epsilon_spent": 0.557514218028555,
      "total_epsilon": 0.557514218028555
    },
    {
      "step": 1127,
      "optim_step": 141,
      "loss": 1.8725345134735107,
      "grad_norm": 5.273062229156494,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 633.0589850000479,
      "epsilon_spent": 0.5579210197520601,
      "total_epsilon": 0.5579210197520601
    },
    {
      "step": 1135,
      "optim_step": 142,
      "loss": 5.421477317810059,
      "grad_norm": 27.993160247802734,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 532.7923020000753,
      "epsilon_spent": 0.5583278214755653,
      "total_epsilon": 0.5583278214755653
    },
    {
      "step": 1143,
      "optim_step": 143,
      "loss": 3.4182674884796143,
      "grad_norm": 17.169832229614258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 549.3195829999422,
      "epsilon_spent": 0.5586009705941266,
      "total_epsilon": 0.5586009705941266
    },
    {
      "step": 1151,
      "optim_step": 144,
      "loss": 2.8151843547821045,
      "grad_norm": 13.21285343170166,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 573.0942860000141,
      "epsilon_spent": 0.5588477270747688,
      "total_epsilon": 0.5588477270747688
    },
    {
      "step": 1159,
      "optim_step": 145,
      "loss": 4.623043060302734,
      "grad_norm": 16.138282775878906,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 588.0751930000088,
      "epsilon_spent": 0.559094483555411,
      "total_epsilon": 0.559094483555411
    },
    {
      "step": 1167,
      "optim_step": 146,
      "loss": 4.301201820373535,
      "grad_norm": 15.215173721313477,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 697.3070599999573,
      "epsilon_spent": 0.5593412400360533,
      "total_epsilon": 0.5593412400360533
    },
    {
      "step": 1175,
      "optim_step": 147,
      "loss": 3.5305557250976562,
      "grad_norm": 15.004644393920898,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 570.8063689999108,
      "epsilon_spent": 0.5595879965166957,
      "total_epsilon": 0.5595879965166957
    },
    {
      "step": 1183,
      "optim_step": 148,
      "loss": 5.219594478607178,
      "grad_norm": 19.461206436157227,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 575.1549780000005,
      "epsilon_spent": 0.5598347529973379,
      "total_epsilon": 0.5598347529973379
    },
    {
      "step": 1191,
      "optim_step": 149,
      "loss": 3.348968505859375,
      "grad_norm": 16.943029403686523,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 691.0687380000127,
      "epsilon_spent": 0.5600815094779801,
      "total_epsilon": 0.5600815094779801
    },
    {
      "step": 1199,
      "optim_step": 150,
      "loss": 3.4027271270751953,
      "grad_norm": 10.16372013092041,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 565.0796620000165,
      "epsilon_spent": 0.5603282659586224,
      "total_epsilon": 0.5603282659586224
    },
    {
      "step": 1207,
      "optim_step": 151,
      "loss": 4.521592617034912,
      "grad_norm": 21.029190063476562,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 548.5058430000436,
      "epsilon_spent": 0.5605750224392647,
      "total_epsilon": 0.5605750224392647
    },
    {
      "step": 1215,
      "optim_step": 152,
      "loss": 3.662945508956909,
      "grad_norm": 16.3325138092041,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 635.2442749999909,
      "epsilon_spent": 0.5608217789199069,
      "total_epsilon": 0.5608217789199069
    },
    {
      "step": 1223,
      "optim_step": 153,
      "loss": 4.146587371826172,
      "grad_norm": 13.607993125915527,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 562.4132080000663,
      "epsilon_spent": 0.5610685354005491,
      "total_epsilon": 0.5610685354005491
    },
    {
      "step": 1231,
      "optim_step": 154,
      "loss": 3.8118014335632324,
      "grad_norm": 17.82179069519043,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 563.2659000000331,
      "epsilon_spent": 0.5613152918811914,
      "total_epsilon": 0.5613152918811914
    },
    {
      "step": 1239,
      "optim_step": 155,
      "loss": 3.087144136428833,
      "grad_norm": 10.330161094665527,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 549.4760679999899,
      "epsilon_spent": 0.5615620483618338,
      "total_epsilon": 0.5615620483618338
    },
    {
      "step": 1247,
      "optim_step": 156,
      "loss": 1.2187860012054443,
      "grad_norm": 5.2682318687438965,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 566.7359010000155,
      "epsilon_spent": 0.561808804842476,
      "total_epsilon": 0.561808804842476
    },
    {
      "step": 1255,
      "optim_step": 157,
      "loss": 3.0455219745635986,
      "grad_norm": 13.873665809631348,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 582.4386470001173,
      "epsilon_spent": 0.5620555613231182,
      "total_epsilon": 0.5620555613231182
    },
    {
      "step": 1263,
      "optim_step": 158,
      "loss": 2.911888360977173,
      "grad_norm": 12.800084114074707,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 551.8775850000566,
      "epsilon_spent": 0.5623023178037605,
      "total_epsilon": 0.5623023178037605
    },
    {
      "step": 1271,
      "optim_step": 159,
      "loss": 3.75699782371521,
      "grad_norm": 17.207141876220703,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 552.7740999998514,
      "epsilon_spent": 0.5625490742844028,
      "total_epsilon": 0.5625490742844028
    },
    {
      "step": 1279,
      "optim_step": 160,
      "loss": 4.37067174911499,
      "grad_norm": 15.411373138427734,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 557.5030709999282,
      "epsilon_spent": 0.562795830765045,
      "total_epsilon": 0.562795830765045
    },
    {
      "step": 1287,
      "optim_step": 161,
      "loss": 4.254101276397705,
      "grad_norm": 17.773313522338867,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 597.9658159999417,
      "epsilon_spent": 0.5630425872456872,
      "total_epsilon": 0.5630425872456872
    },
    {
      "step": 1295,
      "optim_step": 162,
      "loss": 2.968111753463745,
      "grad_norm": 12.071781158447266,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 559.3759930000033,
      "epsilon_spent": 0.5632893437263295,
      "total_epsilon": 0.5632893437263295
    },
    {
      "step": 1303,
      "optim_step": 163,
      "loss": 3.810875177383423,
      "grad_norm": 13.537741661071777,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 556.0029360001408,
      "epsilon_spent": 0.5635361002069719,
      "total_epsilon": 0.5635361002069719
    },
    {
      "step": 1311,
      "optim_step": 164,
      "loss": 5.148244380950928,
      "grad_norm": 20.575721740722656,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 545.2704869999252,
      "epsilon_spent": 0.5637828566876141,
      "total_epsilon": 0.5637828566876141
    },
    {
      "step": 1319,
      "optim_step": 165,
      "loss": 2.142691135406494,
      "grad_norm": 1.4131779670715332,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 503.1066369999735,
      "epsilon_spent": 0.5640296131682563,
      "total_epsilon": 0.5640296131682563
    },
    {
      "step": 1327,
      "optim_step": 166,
      "loss": 3.033709764480591,
      "grad_norm": 13.148448944091797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 558.1410620000042,
      "epsilon_spent": 0.5642763696488986,
      "total_epsilon": 0.5642763696488986
    },
    {
      "step": 1335,
      "optim_step": 167,
      "loss": 5.177223205566406,
      "grad_norm": 17.633052825927734,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 586.83613900007,
      "epsilon_spent": 0.5645231261295409,
      "total_epsilon": 0.5645231261295409
    },
    {
      "step": 1343,
      "optim_step": 168,
      "loss": 1.4445672035217285,
      "grad_norm": 1.3390614986419678,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 519.0878189998784,
      "epsilon_spent": 0.5647698826101831,
      "total_epsilon": 0.5647698826101831
    },
    {
      "step": 1351,
      "optim_step": 169,
      "loss": 3.8514404296875,
      "grad_norm": 16.113176345825195,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 556.1832420000883,
      "epsilon_spent": 0.5650166390908253,
      "total_epsilon": 0.5650166390908253
    },
    {
      "step": 1359,
      "optim_step": 170,
      "loss": 2.142935037612915,
      "grad_norm": 5.5687127113342285,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 567.8275149998626,
      "epsilon_spent": 0.5652633955714677,
      "total_epsilon": 0.5652633955714677
    },
    {
      "step": 1367,
      "optim_step": 171,
      "loss": 3.799365520477295,
      "grad_norm": 11.68941879272461,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 535.3393790001064,
      "epsilon_spent": 0.56551015205211,
      "total_epsilon": 0.56551015205211
    },
    {
      "step": 1375,
      "optim_step": 172,
      "loss": 4.136000156402588,
      "grad_norm": 19.120601654052734,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 557.5250699998833,
      "epsilon_spent": 0.5657569085327522,
      "total_epsilon": 0.5657569085327522
    },
    {
      "step": 1383,
      "optim_step": 173,
      "loss": 3.5669126510620117,
      "grad_norm": 16.359424591064453,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 555.441146000021,
      "epsilon_spent": 0.5660036650133944,
      "total_epsilon": 0.5660036650133944
    },
    {
      "step": 1391,
      "optim_step": 174,
      "loss": 4.308845043182373,
      "grad_norm": 12.69066333770752,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 529.4811039998422,
      "epsilon_spent": 0.5662504214940367,
      "total_epsilon": 0.5662504214940367
    },
    {
      "step": 1399,
      "optim_step": 175,
      "loss": 3.42445969581604,
      "grad_norm": 15.280909538269043,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 556.992874000116,
      "epsilon_spent": 0.566497177974679,
      "total_epsilon": 0.566497177974679
    },
    {
      "step": 1407,
      "optim_step": 176,
      "loss": 2.8409206867218018,
      "grad_norm": 8.977158546447754,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 552.0152080000571,
      "epsilon_spent": 0.5667439344553212,
      "total_epsilon": 0.5667439344553212
    },
    {
      "step": 1415,
      "optim_step": 177,
      "loss": 3.6891250610351562,
      "grad_norm": 19.01872444152832,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 582.8307189999578,
      "epsilon_spent": 0.5669906909359634,
      "total_epsilon": 0.5669906909359634
    },
    {
      "step": 1423,
      "optim_step": 178,
      "loss": 1.7764836549758911,
      "grad_norm": 1.5864566564559937,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 511.75126599991927,
      "epsilon_spent": 0.5672374474166058,
      "total_epsilon": 0.5672374474166058
    },
    {
      "step": 1431,
      "optim_step": 179,
      "loss": 3.692577362060547,
      "grad_norm": 17.820510864257812,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 612.8664870000193,
      "epsilon_spent": 0.5674842038972481,
      "total_epsilon": 0.5674842038972481
    },
    {
      "step": 1439,
      "optim_step": 180,
      "loss": 3.638737678527832,
      "grad_norm": 17.701335906982422,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 539.8397480000767,
      "epsilon_spent": 0.5677309603778903,
      "total_epsilon": 0.5677309603778903
    },
    {
      "step": 1447,
      "optim_step": 181,
      "loss": 4.351855278015137,
      "grad_norm": 18.279800415039062,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 598.0127339998944,
      "epsilon_spent": 0.5679777168585325,
      "total_epsilon": 0.5679777168585325
    },
    {
      "step": 1455,
      "optim_step": 182,
      "loss": 4.745367527008057,
      "grad_norm": 16.71177101135254,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 561.930398999948,
      "epsilon_spent": 0.5682244733391748,
      "total_epsilon": 0.5682244733391748
    },
    {
      "step": 1463,
      "optim_step": 183,
      "loss": 5.569276332855225,
      "grad_norm": 19.89630699157715,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 565.1228010001432,
      "epsilon_spent": 0.5684712298198171,
      "total_epsilon": 0.5684712298198171
    },
    {
      "step": 1471,
      "optim_step": 184,
      "loss": 4.783003807067871,
      "grad_norm": 19.265911102294922,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 558.039172000008,
      "epsilon_spent": 0.5687179863004593,
      "total_epsilon": 0.5687179863004593
    },
    {
      "step": 1479,
      "optim_step": 185,
      "loss": 2.3147764205932617,
      "grad_norm": 11.170145034790039,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 563.7482829999954,
      "epsilon_spent": 0.5689647427811015,
      "total_epsilon": 0.5689647427811015
    },
    {
      "step": 1487,
      "optim_step": 186,
      "loss": 3.961301565170288,
      "grad_norm": 14.647530555725098,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 558.3566979998977,
      "epsilon_spent": 0.5692114992617439,
      "total_epsilon": 0.5692114992617439
    },
    {
      "step": 1495,
      "optim_step": 187,
      "loss": 2.850647211074829,
      "grad_norm": 11.576233863830566,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 549.8092350001116,
      "epsilon_spent": 0.5694582557423862,
      "total_epsilon": 0.5694582557423862
    },
    {
      "step": 1503,
      "optim_step": 188,
      "loss": 1.4280163049697876,
      "grad_norm": 4.04925012588501,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 562.0726589997957,
      "epsilon_spent": 0.5697050122230284,
      "total_epsilon": 0.5697050122230284
    },
    {
      "step": 1511,
      "optim_step": 189,
      "loss": 2.913674831390381,
      "grad_norm": 13.874958038330078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 566.1876619999475,
      "epsilon_spent": 0.5699517687036706,
      "total_epsilon": 0.5699517687036706
    },
    {
      "step": 1519,
      "optim_step": 190,
      "loss": 5.036205291748047,
      "grad_norm": 21.145336151123047,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 583.0990510000902,
      "epsilon_spent": 0.5701985251843129,
      "total_epsilon": 0.5701985251843129
    },
    {
      "step": 1527,
      "optim_step": 191,
      "loss": 3.314992666244507,
      "grad_norm": 17.098920822143555,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 526.6983929998332,
      "epsilon_spent": 0.5704452816649552,
      "total_epsilon": 0.5704452816649552
    },
    {
      "step": 1535,
      "optim_step": 192,
      "loss": 4.457148551940918,
      "grad_norm": 15.109766006469727,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 600.7208640000954,
      "epsilon_spent": 0.5706920381455974,
      "total_epsilon": 0.5706920381455974
    },
    {
      "step": 1543,
      "optim_step": 193,
      "loss": 1.1626511812210083,
      "grad_norm": 1.2473469972610474,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 517.761074999953,
      "epsilon_spent": 0.5709387946262396,
      "total_epsilon": 0.5709387946262396
    },
    {
      "step": 1551,
      "optim_step": 194,
      "loss": 4.545987606048584,
      "grad_norm": 18.994159698486328,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.8430239999507,
      "epsilon_spent": 0.571185551106882,
      "total_epsilon": 0.571185551106882
    },
    {
      "step": 1559,
      "optim_step": 195,
      "loss": 3.932720184326172,
      "grad_norm": 18.76692771911621,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 566.7940100001942,
      "epsilon_spent": 0.5714323075875243,
      "total_epsilon": 0.5714323075875243
    },
    {
      "step": 1567,
      "optim_step": 196,
      "loss": 3.2010717391967773,
      "grad_norm": 13.91039752960205,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 617.4902889999885,
      "epsilon_spent": 0.5716790640681665,
      "total_epsilon": 0.5716790640681665
    },
    {
      "step": 1575,
      "optim_step": 197,
      "loss": 2.310398578643799,
      "grad_norm": 1.3487526178359985,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 509.54912200018043,
      "epsilon_spent": 0.5719258205488087,
      "total_epsilon": 0.5719258205488087
    },
    {
      "step": 1583,
      "optim_step": 198,
      "loss": 4.967655181884766,
      "grad_norm": 15.162691116333008,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 522.2282890001679,
      "epsilon_spent": 0.572172577029451,
      "total_epsilon": 0.572172577029451
    },
    {
      "step": 1591,
      "optim_step": 199,
      "loss": 2.338526487350464,
      "grad_norm": 8.069809913635254,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 689.890190999904,
      "epsilon_spent": 0.5724193335100933,
      "total_epsilon": 0.5724193335100933
    },
    {
      "step": 1599,
      "optim_step": 200,
      "loss": 4.557968616485596,
      "grad_norm": 21.030118942260742,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 555.0266039999769,
      "epsilon_spent": 0.5726660899907355,
      "total_epsilon": 0.5726660899907355
    },
    {
      "step": 1607,
      "optim_step": 201,
      "loss": 3.021461248397827,
      "grad_norm": 15.031747817993164,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 543.1815449999249,
      "epsilon_spent": 0.5729128464713777,
      "total_epsilon": 0.5729128464713777
    },
    {
      "step": 1615,
      "optim_step": 202,
      "loss": 3.1380622386932373,
      "grad_norm": 15.960287094116211,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 578.9298869999584,
      "epsilon_spent": 0.5731596029520201,
      "total_epsilon": 0.5731596029520201
    },
    {
      "step": 1623,
      "optim_step": 203,
      "loss": 4.695889472961426,
      "grad_norm": 20.26284408569336,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 566.1451500000112,
      "epsilon_spent": 0.5734063594326624,
      "total_epsilon": 0.5734063594326624
    },
    {
      "step": 1631,
      "optim_step": 204,
      "loss": 4.196211814880371,
      "grad_norm": 16.305652618408203,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 563.7903070000903,
      "epsilon_spent": 0.5736531159133046,
      "total_epsilon": 0.5736531159133046
    },
    {
      "step": 1639,
      "optim_step": 205,
      "loss": 3.9375813007354736,
      "grad_norm": 18.37042808532715,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 522.6370809998571,
      "epsilon_spent": 0.5738998723939468,
      "total_epsilon": 0.5738998723939468
    },
    {
      "step": 1647,
      "optim_step": 206,
      "loss": 1.7009505033493042,
      "grad_norm": 3.5051560401916504,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 542.5410760001341,
      "epsilon_spent": 0.5741466288745891,
      "total_epsilon": 0.5741466288745891
    },
    {
      "step": 1655,
      "optim_step": 207,
      "loss": 3.081397294998169,
      "grad_norm": 12.583149909973145,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 580.3945640000165,
      "epsilon_spent": 0.5743933853552314,
      "total_epsilon": 0.5743933853552314
    },
    {
      "step": 1663,
      "optim_step": 208,
      "loss": 1.732068419456482,
      "grad_norm": 3.0289602279663086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 547.923320000109,
      "epsilon_spent": 0.5746401418358736,
      "total_epsilon": 0.5746401418358736
    },
    {
      "step": 1671,
      "optim_step": 209,
      "loss": 1.066400408744812,
      "grad_norm": 1.27497136592865,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 574.0041939998264,
      "epsilon_spent": 0.5748868983165158,
      "total_epsilon": 0.5748868983165158
    },
    {
      "step": 1679,
      "optim_step": 210,
      "loss": 4.166412353515625,
      "grad_norm": 18.838441848754883,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 573.9287769999919,
      "epsilon_spent": 0.5751336547971582,
      "total_epsilon": 0.5751336547971582
    },
    {
      "step": 1687,
      "optim_step": 211,
      "loss": 3.873115301132202,
      "grad_norm": 13.042936325073242,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 624.1215970001122,
      "epsilon_spent": 0.5753804112778005,
      "total_epsilon": 0.5753804112778005
    },
    {
      "step": 1695,
      "optim_step": 212,
      "loss": 4.286767482757568,
      "grad_norm": 14.811592102050781,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 533.8539169999876,
      "epsilon_spent": 0.5756271677584427,
      "total_epsilon": 0.5756271677584427
    },
    {
      "step": 1703,
      "optim_step": 213,
      "loss": 3.493651866912842,
      "grad_norm": 18.630998611450195,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 561.1292159999266,
      "epsilon_spent": 0.5758739242390849,
      "total_epsilon": 0.5758739242390849
    },
    {
      "step": 1711,
      "optim_step": 214,
      "loss": 3.4129996299743652,
      "grad_norm": 14.492719650268555,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 518.4203600001638,
      "epsilon_spent": 0.5761206807197272,
      "total_epsilon": 0.5761206807197272
    },
    {
      "step": 1719,
      "optim_step": 215,
      "loss": 4.77842378616333,
      "grad_norm": 20.652936935424805,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 524.5798249998188,
      "epsilon_spent": 0.5763674372003695,
      "total_epsilon": 0.5763674372003695
    },
    {
      "step": 1727,
      "optim_step": 216,
      "loss": 3.4535746574401855,
      "grad_norm": 15.166464805603027,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 599.4693370000732,
      "epsilon_spent": 0.5766141936810117,
      "total_epsilon": 0.5766141936810117
    },
    {
      "step": 1735,
      "optim_step": 217,
      "loss": 3.3204739093780518,
      "grad_norm": 15.325610160827637,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 567.0336819998738,
      "epsilon_spent": 0.576860950161654,
      "total_epsilon": 0.576860950161654
    },
    {
      "step": 1743,
      "optim_step": 218,
      "loss": 1.3038673400878906,
      "grad_norm": 1.2451434135437012,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 550.3889799999797,
      "epsilon_spent": 0.5771077066422963,
      "total_epsilon": 0.5771077066422963
    },
    {
      "step": 1751,
      "optim_step": 219,
      "loss": 4.234033107757568,
      "grad_norm": 20.03598403930664,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 570.8640420000393,
      "epsilon_spent": 0.5773544631229386,
      "total_epsilon": 0.5773544631229386
    },
    {
      "step": 1759,
      "optim_step": 220,
      "loss": 2.1678836345672607,
      "grad_norm": 1.3524905443191528,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 494.1548430001603,
      "epsilon_spent": 0.5776012196035808,
      "total_epsilon": 0.5776012196035808
    },
    {
      "step": 1767,
      "optim_step": 221,
      "loss": 2.0440313816070557,
      "grad_norm": 9.822648048400879,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 572.6133599998775,
      "epsilon_spent": 0.577847976084223,
      "total_epsilon": 0.577847976084223
    },
    {
      "step": 1775,
      "optim_step": 222,
      "loss": 3.9683239459991455,
      "grad_norm": 12.436944007873535,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 524.6327079998991,
      "epsilon_spent": 0.5780947325648653,
      "total_epsilon": 0.5780947325648653
    },
    {
      "step": 1783,
      "optim_step": 223,
      "loss": 4.7870049476623535,
      "grad_norm": 15.188542366027832,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 544.8071049997907,
      "epsilon_spent": 0.5783414890455076,
      "total_epsilon": 0.5783414890455076
    },
    {
      "step": 1791,
      "optim_step": 224,
      "loss": 4.199743270874023,
      "grad_norm": 12.487452507019043,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 578.6593919999632,
      "epsilon_spent": 0.5785882455261498,
      "total_epsilon": 0.5785882455261498
    },
    {
      "step": 1799,
      "optim_step": 225,
      "loss": 2.9635939598083496,
      "grad_norm": 9.03754997253418,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 559.6601329998521,
      "epsilon_spent": 0.578835002006792,
      "total_epsilon": 0.578835002006792
    },
    {
      "step": 1807,
      "optim_step": 226,
      "loss": 3.5662171840667725,
      "grad_norm": 16.448381423950195,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 548.4361500000432,
      "epsilon_spent": 0.5790817584874344,
      "total_epsilon": 0.5790817584874344
    },
    {
      "step": 1815,
      "optim_step": 227,
      "loss": 3.2856523990631104,
      "grad_norm": 13.966154098510742,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 592.2101800001656,
      "epsilon_spent": 0.5793285149680767,
      "total_epsilon": 0.5793285149680767
    },
    {
      "step": 1823,
      "optim_step": 228,
      "loss": 4.1182169914245605,
      "grad_norm": 19.411930084228516,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 573.2899590000216,
      "epsilon_spent": 0.5795752714487189,
      "total_epsilon": 0.5795752714487189
    },
    {
      "step": 1831,
      "optim_step": 229,
      "loss": 5.693039894104004,
      "grad_norm": 22.9724178314209,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 563.5948009999083,
      "epsilon_spent": 0.5798220279293611,
      "total_epsilon": 0.5798220279293611
    },
    {
      "step": 1839,
      "optim_step": 230,
      "loss": 4.192073345184326,
      "grad_norm": 16.752756118774414,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 586.5619570001854,
      "epsilon_spent": 0.5800687844100034,
      "total_epsilon": 0.5800687844100034
    },
    {
      "step": 1847,
      "optim_step": 231,
      "loss": 3.2073111534118652,
      "grad_norm": 13.87540340423584,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 596.9064280000111,
      "epsilon_spent": 0.5803155408906457,
      "total_epsilon": 0.5803155408906457
    },
    {
      "step": 1855,
      "optim_step": 232,
      "loss": 4.279849052429199,
      "grad_norm": 17.535215377807617,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 587.9678060000515,
      "epsilon_spent": 0.580562297371288,
      "total_epsilon": 0.580562297371288
    },
    {
      "step": 1863,
      "optim_step": 233,
      "loss": 4.904327869415283,
      "grad_norm": 20.421424865722656,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 550.4027810000025,
      "epsilon_spent": 0.5808090538519302,
      "total_epsilon": 0.5808090538519302
    },
    {
      "step": 1871,
      "optim_step": 234,
      "loss": 1.9648540019989014,
      "grad_norm": 1.3579717874526978,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 508.3178060001501,
      "epsilon_spent": 0.5810558103325725,
      "total_epsilon": 0.5810558103325725
    },
    {
      "step": 1879,
      "optim_step": 235,
      "loss": 3.072985887527466,
      "grad_norm": 10.231927871704102,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 616.849208000076,
      "epsilon_spent": 0.5813025668132148,
      "total_epsilon": 0.5813025668132148
    },
    {
      "step": 1887,
      "optim_step": 236,
      "loss": 5.113671779632568,
      "grad_norm": 24.74612045288086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 520.244380999884,
      "epsilon_spent": 0.581549323293857,
      "total_epsilon": 0.581549323293857
    },
    {
      "step": 1895,
      "optim_step": 237,
      "loss": 4.245460510253906,
      "grad_norm": 12.620811462402344,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 595.1086000000032,
      "epsilon_spent": 0.5817960797744992,
      "total_epsilon": 0.5817960797744992
    },
    {
      "step": 1903,
      "optim_step": 238,
      "loss": 3.6363365650177,
      "grad_norm": 17.992931365966797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 543.5300809999717,
      "epsilon_spent": 0.5820428362551415,
      "total_epsilon": 0.5820428362551415
    },
    {
      "step": 1911,
      "optim_step": 239,
      "loss": 2.516883611679077,
      "grad_norm": 13.611559867858887,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 581.2478309999278,
      "epsilon_spent": 0.5822895927357838,
      "total_epsilon": 0.5822895927357838
    },
    {
      "step": 1919,
      "optim_step": 240,
      "loss": 3.3531672954559326,
      "grad_norm": 16.51439666748047,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 557.404527000017,
      "epsilon_spent": 0.582536349216426,
      "total_epsilon": 0.582536349216426
    },
    {
      "step": 1927,
      "optim_step": 241,
      "loss": 3.0924203395843506,
      "grad_norm": 12.191473007202148,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 533.1277149998641,
      "epsilon_spent": 0.5827831056970683,
      "total_epsilon": 0.5827831056970683
    },
    {
      "step": 1935,
      "optim_step": 242,
      "loss": 4.805961608886719,
      "grad_norm": 18.550399780273438,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 573.544044000073,
      "epsilon_spent": 0.5830298621777106,
      "total_epsilon": 0.5830298621777106
    },
    {
      "step": 1943,
      "optim_step": 243,
      "loss": 3.2381629943847656,
      "grad_norm": 11.330731391906738,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 579.0685940000913,
      "epsilon_spent": 0.5832766186583529,
      "total_epsilon": 0.5832766186583529
    },
    {
      "step": 1951,
      "optim_step": 244,
      "loss": 4.041508197784424,
      "grad_norm": 13.029563903808594,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 548.7459309999849,
      "epsilon_spent": 0.5835233751389951,
      "total_epsilon": 0.5835233751389951
    },
    {
      "step": 1959,
      "optim_step": 245,
      "loss": 3.6198389530181885,
      "grad_norm": 15.481618881225586,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 569.1740479999225,
      "epsilon_spent": 0.5837701316196373,
      "total_epsilon": 0.5837701316196373
    },
    {
      "step": 1967,
      "optim_step": 246,
      "loss": 2.213021993637085,
      "grad_norm": 7.385115623474121,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 560.4218379999111,
      "epsilon_spent": 0.5840168881002796,
      "total_epsilon": 0.5840168881002796
    },
    {
      "step": 1975,
      "optim_step": 247,
      "loss": 1.5136027336120605,
      "grad_norm": 1.3522539138793945,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 580.250992999936,
      "epsilon_spent": 0.584263644580922,
      "total_epsilon": 0.584263644580922
    },
    {
      "step": 1983,
      "optim_step": 248,
      "loss": 3.967944383621216,
      "grad_norm": 12.883946418762207,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 582.3490369998581,
      "epsilon_spent": 0.5845104010615642,
      "total_epsilon": 0.5845104010615642
    },
    {
      "step": 1991,
      "optim_step": 249,
      "loss": 3.628469228744507,
      "grad_norm": 12.258712768554688,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 555.7538430000477,
      "epsilon_spent": 0.5847571575422064,
      "total_epsilon": 0.5847571575422064
    },
    {
      "step": 1999,
      "optim_step": 250,
      "loss": 1.289272427558899,
      "grad_norm": 1.2229199409484863,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 533.2194520001394,
      "epsilon_spent": 0.5850039140228487,
      "total_epsilon": 0.5850039140228487
    }
  ]
}