{
  "adapter_name": "shared_attention",
  "model": "Qwen/Qwen2.5-1.5B",
  "rank": 32,
  "alpha": 64.0,
  "target_modules": [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj",
    "gate_proj",
    "up_proj"
  ],
  "total_steps": 2000,
  "final_loss": 4.469500541687012,
  "best_loss": 1.345075249671936,
  "total_time_seconds": 1614.6,
  "dataset_size": 50000,
  "metrics": [
    {
      "step": 7,
      "optim_step": 1,
      "loss": 4.2289581298828125,
      "grad_norm": 22.455066680908203,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 699.2320030000059,
      "epsilon_spent": 0.354419818714585,
      "total_epsilon": 0.354419818714585
    },
    {
      "step": 15,
      "optim_step": 2,
      "loss": 3.509016752243042,
      "grad_norm": 23.807945251464844,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 837.7872079999946,
      "epsilon_spent": 0.36810773377144784,
      "total_epsilon": 0.36810773377144784
    },
    {
      "step": 23,
      "optim_step": 3,
      "loss": 5.386399269104004,
      "grad_norm": 31.8067684173584,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 700.7534829999997,
      "epsilon_spent": 0.3773084688221571,
      "total_epsilon": 0.3773084688221571
    },
    {
      "step": 31,
      "optim_step": 4,
      "loss": 4.0210089683532715,
      "grad_norm": 24.836528778076172,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 664.8279560000105,
      "epsilon_spent": 0.3831516515027696,
      "total_epsilon": 0.3831516515027696
    },
    {
      "step": 39,
      "optim_step": 5,
      "loss": 3.5673511028289795,
      "grad_norm": 21.36480140686035,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 678.6509380000041,
      "epsilon_spent": 0.38899483418338204,
      "total_epsilon": 0.38899483418338204
    },
    {
      "step": 47,
      "optim_step": 6,
      "loss": 4.369399547576904,
      "grad_norm": 18.494279861450195,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 699.9133529999995,
      "epsilon_spent": 0.39267354263069487,
      "total_epsilon": 0.39267354263069487
    },
    {
      "step": 55,
      "optim_step": 7,
      "loss": 3.2938365936279297,
      "grad_norm": 19.45359992980957,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 685.7111580000037,
      "epsilon_spent": 0.39622168433274496,
      "total_epsilon": 0.39622168433274496
    },
    {
      "step": 63,
      "optim_step": 8,
      "loss": 4.621086597442627,
      "grad_norm": 27.107595443725586,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 658.6965790000079,
      "epsilon_spent": 0.39976982603479505,
      "total_epsilon": 0.39976982603479505
    },
    {
      "step": 71,
      "optim_step": 9,
      "loss": 4.6327643394470215,
      "grad_norm": 28.231456756591797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 696.4996470000102,
      "epsilon_spent": 0.40314620792814915,
      "total_epsilon": 0.40314620792814915
    },
    {
      "step": 79,
      "optim_step": 10,
      "loss": 4.388365745544434,
      "grad_norm": 20.409561157226562,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 677.7179740000037,
      "epsilon_spent": 0.40529976634620196,
      "total_epsilon": 0.40529976634620196
    },
    {
      "step": 87,
      "optim_step": 11,
      "loss": 4.58159875869751,
      "grad_norm": 26.198118209838867,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 714.9481320000035,
      "epsilon_spent": 0.4074533247642547,
      "total_epsilon": 0.4074533247642547
    },
    {
      "step": 95,
      "optim_step": 12,
      "loss": 4.67840051651001,
      "grad_norm": 26.697757720947266,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 721.7538800000227,
      "epsilon_spent": 0.4096068831823075,
      "total_epsilon": 0.4096068831823075
    },
    {
      "step": 103,
      "optim_step": 13,
      "loss": 2.4915931224823,
      "grad_norm": 16.50916862487793,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 720.488529000022,
      "epsilon_spent": 0.41176044160036024,
      "total_epsilon": 0.41176044160036024
    },
    {
      "step": 111,
      "optim_step": 14,
      "loss": 4.09916877746582,
      "grad_norm": 22.39085578918457,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 791.1547780000205,
      "epsilon_spent": 0.413914000018413,
      "total_epsilon": 0.413914000018413
    },
    {
      "step": 119,
      "optim_step": 15,
      "loss": 2.903409481048584,
      "grad_norm": 16.698989868164062,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 694.1746100000046,
      "epsilon_spent": 0.4160675584364658,
      "total_epsilon": 0.4160675584364658
    },
    {
      "step": 127,
      "optim_step": 16,
      "loss": 1.451103687286377,
      "grad_norm": 1.5327731370925903,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 672.2832369999878,
      "epsilon_spent": 0.41790546784382376,
      "total_epsilon": 0.41790546784382376
    },
    {
      "step": 135,
      "optim_step": 17,
      "loss": 2.5262115001678467,
      "grad_norm": 15.2689790725708,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 707.4182329999985,
      "epsilon_spent": 0.4192122202199028,
      "total_epsilon": 0.4192122202199028
    },
    {
      "step": 143,
      "optim_step": 18,
      "loss": 4.636284828186035,
      "grad_norm": 27.517349243164062,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 787.0483730000046,
      "epsilon_spent": 0.4205189725959818,
      "total_epsilon": 0.4205189725959818
    },
    {
      "step": 151,
      "optim_step": 19,
      "loss": 3.3697712421417236,
      "grad_norm": 22.380338668823242,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 702.4675469999977,
      "epsilon_spent": 0.4218257249720608,
      "total_epsilon": 0.4218257249720608
    },
    {
      "step": 159,
      "optim_step": 20,
      "loss": 4.148463249206543,
      "grad_norm": 21.633079528808594,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 747.796706999992,
      "epsilon_spent": 0.4231324773481398,
      "total_epsilon": 0.4231324773481398
    },
    {
      "step": 167,
      "optim_step": 21,
      "loss": 3.8216607570648193,
      "grad_norm": 26.838380813598633,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 727.1393880000119,
      "epsilon_spent": 0.4244392297242188,
      "total_epsilon": 0.4244392297242188
    },
    {
      "step": 175,
      "optim_step": 22,
      "loss": 6.72619104385376,
      "grad_norm": 37.72833251953125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 700.6755479999924,
      "epsilon_spent": 0.42574598210029785,
      "total_epsilon": 0.42574598210029785
    },
    {
      "step": 183,
      "optim_step": 23,
      "loss": 3.7824645042419434,
      "grad_norm": 17.173601150512695,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 791.9712929999889,
      "epsilon_spent": 0.4270527344763768,
      "total_epsilon": 0.4270527344763768
    },
    {
      "step": 191,
      "optim_step": 24,
      "loss": 2.1523683071136475,
      "grad_norm": 10.003662109375,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 809.8395769999911,
      "epsilon_spent": 0.42835948685245584,
      "total_epsilon": 0.42835948685245584
    },
    {
      "step": 199,
      "optim_step": 25,
      "loss": 3.4305925369262695,
      "grad_norm": 22.607463836669922,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 771.0828590000176,
      "epsilon_spent": 0.42966623922853486,
      "total_epsilon": 0.42966623922853486
    },
    {
      "step": 207,
      "optim_step": 26,
      "loss": 4.897823333740234,
      "grad_norm": 22.57809066772461,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 740.221780000013,
      "epsilon_spent": 0.4309729916046139,
      "total_epsilon": 0.4309729916046139
    },
    {
      "step": 215,
      "optim_step": 27,
      "loss": 3.774332046508789,
      "grad_norm": 23.088329315185547,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 700.7888710000145,
      "epsilon_spent": 0.43227974398069285,
      "total_epsilon": 0.43227974398069285
    },
    {
      "step": 223,
      "optim_step": 28,
      "loss": 4.367565155029297,
      "grad_norm": 23.288658142089844,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 844.3797359999792,
      "epsilon_spent": 0.43337400048827285,
      "total_epsilon": 0.43337400048827285
    },
    {
      "step": 231,
      "optim_step": 29,
      "loss": 2.477522850036621,
      "grad_norm": 15.173298835754395,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 749.9065089999988,
      "epsilon_spent": 0.4341667894534532,
      "total_epsilon": 0.4341667894534532
    },
    {
      "step": 239,
      "optim_step": 30,
      "loss": 1.7162573337554932,
      "grad_norm": 1.6078485250473022,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 636.6606279999871,
      "epsilon_spent": 0.4349595784186336,
      "total_epsilon": 0.4349595784186336
    },
    {
      "step": 247,
      "optim_step": 31,
      "loss": 3.4132251739501953,
      "grad_norm": 21.161577224731445,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 696.1720120000052,
      "epsilon_spent": 0.43575236738381395,
      "total_epsilon": 0.43575236738381395
    },
    {
      "step": 255,
      "optim_step": 32,
      "loss": 3.9127068519592285,
      "grad_norm": 23.351268768310547,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 731.6795890000094,
      "epsilon_spent": 0.4365451563489943,
      "total_epsilon": 0.4365451563489943
    },
    {
      "step": 263,
      "optim_step": 33,
      "loss": 3.645723819732666,
      "grad_norm": 24.251474380493164,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 724.9202620000119,
      "epsilon_spent": 0.4373379453141747,
      "total_epsilon": 0.4373379453141747
    },
    {
      "step": 271,
      "optim_step": 34,
      "loss": 3.3971385955810547,
      "grad_norm": 22.567781448364258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 732.1894680000014,
      "epsilon_spent": 0.43813073427935506,
      "total_epsilon": 0.43813073427935506
    },
    {
      "step": 279,
      "optim_step": 35,
      "loss": 4.660477638244629,
      "grad_norm": 26.273536682128906,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 715.098619999992,
      "epsilon_spent": 0.43892352324453543,
      "total_epsilon": 0.43892352324453543
    },
    {
      "step": 287,
      "optim_step": 36,
      "loss": 5.404966354370117,
      "grad_norm": 27.3752498626709,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 713.386866999997,
      "epsilon_spent": 0.4397163122097158,
      "total_epsilon": 0.4397163122097158
    },
    {
      "step": 295,
      "optim_step": 37,
      "loss": 3.4516685009002686,
      "grad_norm": 18.33279037475586,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 712.5065469999754,
      "epsilon_spent": 0.44050910117489617,
      "total_epsilon": 0.44050910117489617
    },
    {
      "step": 303,
      "optim_step": 38,
      "loss": 4.695332050323486,
      "grad_norm": 31.39788246154785,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 701.0142529999825,
      "epsilon_spent": 0.44130189014007654,
      "total_epsilon": 0.44130189014007654
    },
    {
      "step": 311,
      "optim_step": 39,
      "loss": 4.5659332275390625,
      "grad_norm": 24.6549015045166,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 734.0087059999973,
      "epsilon_spent": 0.4420946791052569,
      "total_epsilon": 0.4420946791052569
    },
    {
      "step": 319,
      "optim_step": 40,
      "loss": 4.573750972747803,
      "grad_norm": 23.350942611694336,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 719.0479230000051,
      "epsilon_spent": 0.4428874680704373,
      "total_epsilon": 0.4428874680704373
    },
    {
      "step": 327,
      "optim_step": 41,
      "loss": 1.8955658674240112,
      "grad_norm": 1.8111392259597778,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 654.5347269999979,
      "epsilon_spent": 0.44368025703561764,
      "total_epsilon": 0.44368025703561764
    },
    {
      "step": 335,
      "optim_step": 42,
      "loss": 3.3913514614105225,
      "grad_norm": 19.864030838012695,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.6227279999566,
      "epsilon_spent": 0.444473046000798,
      "total_epsilon": 0.444473046000798
    },
    {
      "step": 343,
      "optim_step": 43,
      "loss": 4.779394149780273,
      "grad_norm": 25.227325439453125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 728.8551379999717,
      "epsilon_spent": 0.4452658349659784,
      "total_epsilon": 0.4452658349659784
    },
    {
      "step": 351,
      "optim_step": 44,
      "loss": 1.9361172914505005,
      "grad_norm": 8.680416107177734,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 722.7288629999862,
      "epsilon_spent": 0.44605862393115875,
      "total_epsilon": 0.44605862393115875
    },
    {
      "step": 359,
      "optim_step": 45,
      "loss": 4.367318153381348,
      "grad_norm": 28.884851455688477,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 723.8393900000233,
      "epsilon_spent": 0.4468514128963391,
      "total_epsilon": 0.4468514128963391
    },
    {
      "step": 367,
      "optim_step": 46,
      "loss": 3.917226552963257,
      "grad_norm": 19.44866180419922,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 725.8069229999933,
      "epsilon_spent": 0.4476442018615195,
      "total_epsilon": 0.4476442018615195
    },
    {
      "step": 375,
      "optim_step": 47,
      "loss": 4.042662143707275,
      "grad_norm": 22.54466438293457,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 755.53443900003,
      "epsilon_spent": 0.44843699082669986,
      "total_epsilon": 0.44843699082669986
    },
    {
      "step": 383,
      "optim_step": 48,
      "loss": 4.044190406799316,
      "grad_norm": 23.47163200378418,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 702.8890839999917,
      "epsilon_spent": 0.4492297797918802,
      "total_epsilon": 0.4492297797918802
    },
    {
      "step": 391,
      "optim_step": 49,
      "loss": 6.107580184936523,
      "grad_norm": 31.07805061340332,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 708.0313359999764,
      "epsilon_spent": 0.44997000371957707,
      "total_epsilon": 0.44997000371957707
    },
    {
      "step": 399,
      "optim_step": 50,
      "loss": 4.565626621246338,
      "grad_norm": 26.110593795776367,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 711.6471239999669,
      "epsilon_spent": 0.45045092936996134,
      "total_epsilon": 0.45045092936996134
    },
    {
      "step": 407,
      "optim_step": 51,
      "loss": 4.9844279289245605,
      "grad_norm": 26.63976287841797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 713.8454340000067,
      "epsilon_spent": 0.45093185502034555,
      "total_epsilon": 0.45093185502034555
    },
    {
      "step": 415,
      "optim_step": 52,
      "loss": 2.8532299995422363,
      "grad_norm": 16.161108016967773,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 694.0919559999656,
      "epsilon_spent": 0.4514127806707298,
      "total_epsilon": 0.4514127806707298
    },
    {
      "step": 423,
      "optim_step": 53,
      "loss": 3.982088804244995,
      "grad_norm": 21.421119689941406,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 735.3503580000051,
      "epsilon_spent": 0.4518937063211141,
      "total_epsilon": 0.4518937063211141
    },
    {
      "step": 431,
      "optim_step": 54,
      "loss": 5.2336320877075195,
      "grad_norm": 31.114973068237305,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 698.7807870000324,
      "epsilon_spent": 0.4523746319714983,
      "total_epsilon": 0.4523746319714983
    },
    {
      "step": 439,
      "optim_step": 55,
      "loss": 3.4747977256774902,
      "grad_norm": 19.500551223754883,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 708.7811240000406,
      "epsilon_spent": 0.45285555762188257,
      "total_epsilon": 0.45285555762188257
    },
    {
      "step": 447,
      "optim_step": 56,
      "loss": 2.8079123497009277,
      "grad_norm": 17.538820266723633,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 712.9079360000219,
      "epsilon_spent": 0.4533364832722668,
      "total_epsilon": 0.4533364832722668
    },
    {
      "step": 455,
      "optim_step": 57,
      "loss": 3.5707452297210693,
      "grad_norm": 16.21924591064453,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 730.6577829999696,
      "epsilon_spent": 0.45381740892265104,
      "total_epsilon": 0.45381740892265104
    },
    {
      "step": 463,
      "optim_step": 58,
      "loss": 4.828298091888428,
      "grad_norm": 22.97809600830078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 680.6449780000321,
      "epsilon_spent": 0.45429833457303526,
      "total_epsilon": 0.45429833457303526
    },
    {
      "step": 471,
      "optim_step": 59,
      "loss": 3.7323720455169678,
      "grad_norm": 25.849451065063477,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 684.9903130000143,
      "epsilon_spent": 0.4547792602234195,
      "total_epsilon": 0.4547792602234195
    },
    {
      "step": 479,
      "optim_step": 60,
      "loss": 3.403249740600586,
      "grad_norm": 23.089298248291016,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 732.1340630000464,
      "epsilon_spent": 0.4552601858738038,
      "total_epsilon": 0.4552601858738038
    },
    {
      "step": 487,
      "optim_step": 61,
      "loss": 5.595673084259033,
      "grad_norm": 37.51932144165039,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 699.1690599999743,
      "epsilon_spent": 0.455741111524188,
      "total_epsilon": 0.455741111524188
    },
    {
      "step": 495,
      "optim_step": 62,
      "loss": 4.772238731384277,
      "grad_norm": 25.409921646118164,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 713.1865150000181,
      "epsilon_spent": 0.45622203717457227,
      "total_epsilon": 0.45622203717457227
    },
    {
      "step": 503,
      "optim_step": 63,
      "loss": 2.778062343597412,
      "grad_norm": 18.008106231689453,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 682.1811809999758,
      "epsilon_spent": 0.4567029628249565,
      "total_epsilon": 0.4567029628249565
    },
    {
      "step": 511,
      "optim_step": 64,
      "loss": 4.441812992095947,
      "grad_norm": 17.583885192871094,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 732.6236749999566,
      "epsilon_spent": 0.45718388847534075,
      "total_epsilon": 0.45718388847534075
    },
    {
      "step": 519,
      "optim_step": 65,
      "loss": 3.802189588546753,
      "grad_norm": 23.405517578125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 695.1805349999631,
      "epsilon_spent": 0.45766481412572496,
      "total_epsilon": 0.45766481412572496
    },
    {
      "step": 527,
      "optim_step": 66,
      "loss": 4.16668176651001,
      "grad_norm": 23.338991165161133,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 693.0638349999754,
      "epsilon_spent": 0.45814573977610923,
      "total_epsilon": 0.45814573977610923
    },
    {
      "step": 535,
      "optim_step": 67,
      "loss": 2.6124558448791504,
      "grad_norm": 13.121707916259766,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 731.5149799999858,
      "epsilon_spent": 0.45862666542649344,
      "total_epsilon": 0.45862666542649344
    },
    {
      "step": 543,
      "optim_step": 68,
      "loss": 3.9827630519866943,
      "grad_norm": 22.87092399597168,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 710.028670999975,
      "epsilon_spent": 0.4591075910768777,
      "total_epsilon": 0.4591075910768777
    },
    {
      "step": 551,
      "optim_step": 69,
      "loss": 5.316833019256592,
      "grad_norm": 29.587495803833008,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 688.1276459999981,
      "epsilon_spent": 0.4595885167272619,
      "total_epsilon": 0.4595885167272619
    },
    {
      "step": 559,
      "optim_step": 70,
      "loss": 4.259249687194824,
      "grad_norm": 25.66657066345215,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 689.7130590000415,
      "epsilon_spent": 0.4600694423776462,
      "total_epsilon": 0.4600694423776462
    },
    {
      "step": 567,
      "optim_step": 71,
      "loss": 4.246518611907959,
      "grad_norm": 22.70792579650879,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 734.4486830000392,
      "epsilon_spent": 0.4605503680280304,
      "total_epsilon": 0.4605503680280304
    },
    {
      "step": 575,
      "optim_step": 72,
      "loss": 4.947545051574707,
      "grad_norm": 27.127532958984375,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 727.9166200000304,
      "epsilon_spent": 0.46103129367841467,
      "total_epsilon": 0.46103129367841467
    },
    {
      "step": 583,
      "optim_step": 73,
      "loss": 4.178849220275879,
      "grad_norm": 24.25865364074707,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 690.349714999968,
      "epsilon_spent": 0.4615122193287989,
      "total_epsilon": 0.4615122193287989
    },
    {
      "step": 591,
      "optim_step": 74,
      "loss": 5.001342296600342,
      "grad_norm": 29.012929916381836,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 739.9245540000265,
      "epsilon_spent": 0.46199314497918315,
      "total_epsilon": 0.46199314497918315
    },
    {
      "step": 599,
      "optim_step": 75,
      "loss": 5.048158645629883,
      "grad_norm": 32.036685943603516,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 729.2068450000215,
      "epsilon_spent": 0.46247407062956736,
      "total_epsilon": 0.46247407062956736
    },
    {
      "step": 607,
      "optim_step": 76,
      "loss": 4.246553421020508,
      "grad_norm": 25.602771759033203,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 678.5856859999626,
      "epsilon_spent": 0.4629549962799516,
      "total_epsilon": 0.4629549962799516
    },
    {
      "step": 615,
      "optim_step": 77,
      "loss": 6.162003517150879,
      "grad_norm": 36.61408615112305,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 695.3431229999865,
      "epsilon_spent": 0.46343592193033584,
      "total_epsilon": 0.46343592193033584
    },
    {
      "step": 623,
      "optim_step": 78,
      "loss": 1.345075249671936,
      "grad_norm": 1.4740052223205566,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 677.9977580000036,
      "epsilon_spent": 0.4639168475807201,
      "total_epsilon": 0.4639168475807201
    },
    {
      "step": 631,
      "optim_step": 79,
      "loss": 4.049686908721924,
      "grad_norm": 18.534982681274414,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 715.7004319999487,
      "epsilon_spent": 0.4643977732311043,
      "total_epsilon": 0.4643977732311043
    },
    {
      "step": 639,
      "optim_step": 80,
      "loss": 4.628514289855957,
      "grad_norm": 27.226716995239258,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 675.9336000000076,
      "epsilon_spent": 0.4648786988814886,
      "total_epsilon": 0.4648786988814886
    },
    {
      "step": 647,
      "optim_step": 81,
      "loss": 4.539357662200928,
      "grad_norm": 24.904647827148438,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 737.3157749999564,
      "epsilon_spent": 0.4653596245318728,
      "total_epsilon": 0.4653596245318728
    },
    {
      "step": 655,
      "optim_step": 82,
      "loss": 3.6425676345825195,
      "grad_norm": 20.54547119140625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 736.7688250000128,
      "epsilon_spent": 0.46584055018225706,
      "total_epsilon": 0.46584055018225706
    },
    {
      "step": 663,
      "optim_step": 83,
      "loss": 2.9571707248687744,
      "grad_norm": 19.71598243713379,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 675.680089000025,
      "epsilon_spent": 0.4663214758326413,
      "total_epsilon": 0.4663214758326413
    },
    {
      "step": 671,
      "optim_step": 84,
      "loss": 2.2924773693084717,
      "grad_norm": 9.513286590576172,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 697.9625490000672,
      "epsilon_spent": 0.46680240148302554,
      "total_epsilon": 0.46680240148302554
    },
    {
      "step": 679,
      "optim_step": 85,
      "loss": 2.6643824577331543,
      "grad_norm": 16.095918655395508,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 737.0138759999918,
      "epsilon_spent": 0.46728332713340975,
      "total_epsilon": 0.46728332713340975
    },
    {
      "step": 687,
      "optim_step": 86,
      "loss": 2.0053648948669434,
      "grad_norm": 9.336275100708008,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.1103500000172,
      "epsilon_spent": 0.467764252783794,
      "total_epsilon": 0.467764252783794
    },
    {
      "step": 695,
      "optim_step": 87,
      "loss": 3.8091776371002197,
      "grad_norm": 22.81088638305664,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 675.0605050000331,
      "epsilon_spent": 0.4681847781210016,
      "total_epsilon": 0.4681847781210016
    },
    {
      "step": 703,
      "optim_step": 88,
      "loss": 3.800245761871338,
      "grad_norm": 19.53757095336914,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 738.5359909999352,
      "epsilon_spent": 0.4684765017134755,
      "total_epsilon": 0.4684765017134755
    },
    {
      "step": 711,
      "optim_step": 89,
      "loss": 4.020320415496826,
      "grad_norm": 22.04424476623535,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 712.9454070000065,
      "epsilon_spent": 0.4687682253059493,
      "total_epsilon": 0.4687682253059493
    },
    {
      "step": 719,
      "optim_step": 90,
      "loss": 5.347260475158691,
      "grad_norm": 29.138824462890625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 714.3600110000534,
      "epsilon_spent": 0.4690599488984231,
      "total_epsilon": 0.4690599488984231
    },
    {
      "step": 727,
      "optim_step": 91,
      "loss": 3.765737771987915,
      "grad_norm": 26.289775848388672,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 718.5494660000131,
      "epsilon_spent": 0.469351672490897,
      "total_epsilon": 0.469351672490897
    },
    {
      "step": 735,
      "optim_step": 92,
      "loss": 5.078680515289307,
      "grad_norm": 25.379764556884766,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 720.6783829999495,
      "epsilon_spent": 0.4696433960833708,
      "total_epsilon": 0.4696433960833708
    },
    {
      "step": 743,
      "optim_step": 93,
      "loss": 3.4203038215637207,
      "grad_norm": 16.212135314941406,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 672.8692970000338,
      "epsilon_spent": 0.46993511967584467,
      "total_epsilon": 0.46993511967584467
    },
    {
      "step": 751,
      "optim_step": 94,
      "loss": 2.2494208812713623,
      "grad_norm": 8.661246299743652,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 709.1343089999782,
      "epsilon_spent": 0.4702268432683185,
      "total_epsilon": 0.4702268432683185
    },
    {
      "step": 759,
      "optim_step": 95,
      "loss": 5.031069755554199,
      "grad_norm": 31.311992645263672,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 707.7057330000116,
      "epsilon_spent": 0.4705185668607923,
      "total_epsilon": 0.4705185668607923
    },
    {
      "step": 767,
      "optim_step": 96,
      "loss": 3.6638214588165283,
      "grad_norm": 21.896364212036133,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 710.1469250000036,
      "epsilon_spent": 0.47081029045326617,
      "total_epsilon": 0.47081029045326617
    },
    {
      "step": 775,
      "optim_step": 97,
      "loss": 4.557470798492432,
      "grad_norm": 27.072425842285156,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 711.546030999898,
      "epsilon_spent": 0.47110201404574,
      "total_epsilon": 0.47110201404574
    },
    {
      "step": 783,
      "optim_step": 98,
      "loss": 5.212597370147705,
      "grad_norm": 27.987106323242188,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 710.4038920000448,
      "epsilon_spent": 0.4713937376382138,
      "total_epsilon": 0.4713937376382138
    },
    {
      "step": 791,
      "optim_step": 99,
      "loss": 3.632410764694214,
      "grad_norm": 20.8973445892334,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.7841350000444,
      "epsilon_spent": 0.47168546123068766,
      "total_epsilon": 0.47168546123068766
    },
    {
      "step": 799,
      "optim_step": 100,
      "loss": 2.965333938598633,
      "grad_norm": 16.86423110961914,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.288558999996,
      "epsilon_spent": 0.4719771848231615,
      "total_epsilon": 0.4719771848231615
    },
    {
      "step": 807,
      "optim_step": 101,
      "loss": 4.18093729019165,
      "grad_norm": 21.75826072692871,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 711.1427229999663,
      "epsilon_spent": 0.4722689084156353,
      "total_epsilon": 0.4722689084156353
    },
    {
      "step": 815,
      "optim_step": 102,
      "loss": 4.092016696929932,
      "grad_norm": 23.36863136291504,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 718.4282429999485,
      "epsilon_spent": 0.47256063200810916,
      "total_epsilon": 0.47256063200810916
    },
    {
      "step": 823,
      "optim_step": 103,
      "loss": 3.6618666648864746,
      "grad_norm": 20.70053482055664,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 714.7470180000255,
      "epsilon_spent": 0.472852355600583,
      "total_epsilon": 0.472852355600583
    },
    {
      "step": 831,
      "optim_step": 104,
      "loss": 1.6957389116287231,
      "grad_norm": 1.5140312910079956,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 653.6931500000946,
      "epsilon_spent": 0.47314407919305684,
      "total_epsilon": 0.47314407919305684
    },
    {
      "step": 839,
      "optim_step": 105,
      "loss": 4.484297752380371,
      "grad_norm": 20.194124221801758,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 714.4314280000117,
      "epsilon_spent": 0.47343580278553066,
      "total_epsilon": 0.47343580278553066
    },
    {
      "step": 847,
      "optim_step": 106,
      "loss": 3.372835159301758,
      "grad_norm": 24.31460189819336,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 713.997575999997,
      "epsilon_spent": 0.47372752637800447,
      "total_epsilon": 0.47372752637800447
    },
    {
      "step": 855,
      "optim_step": 107,
      "loss": 4.265922546386719,
      "grad_norm": 26.40653419494629,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 712.9099809999389,
      "epsilon_spent": 0.47401924997047834,
      "total_epsilon": 0.47401924997047834
    },
    {
      "step": 863,
      "optim_step": 108,
      "loss": 1.5097707509994507,
      "grad_norm": 2.8544673919677734,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 717.1878120000201,
      "epsilon_spent": 0.47431097356295215,
      "total_epsilon": 0.47431097356295215
    },
    {
      "step": 871,
      "optim_step": 109,
      "loss": 2.3663787841796875,
      "grad_norm": 1.5298477411270142,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 662.3419239999748,
      "epsilon_spent": 0.474602697155426,
      "total_epsilon": 0.474602697155426
    },
    {
      "step": 879,
      "optim_step": 110,
      "loss": 4.19783878326416,
      "grad_norm": 22.110841751098633,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 660.5535350000764,
      "epsilon_spent": 0.47489442074789984,
      "total_epsilon": 0.47489442074789984
    },
    {
      "step": 887,
      "optim_step": 111,
      "loss": 2.438694477081299,
      "grad_norm": 16.97667694091797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 707.8268430000207,
      "epsilon_spent": 0.47518614434037365,
      "total_epsilon": 0.47518614434037365
    },
    {
      "step": 895,
      "optim_step": 112,
      "loss": 4.941221237182617,
      "grad_norm": 27.397884368896484,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.2105960000054,
      "epsilon_spent": 0.4754778679328475,
      "total_epsilon": 0.4754778679328475
    },
    {
      "step": 903,
      "optim_step": 113,
      "loss": 4.589338302612305,
      "grad_norm": 20.91059112548828,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 713.2359910000332,
      "epsilon_spent": 0.47576959152532133,
      "total_epsilon": 0.47576959152532133
    },
    {
      "step": 911,
      "optim_step": 114,
      "loss": 3.0462913513183594,
      "grad_norm": 20.992942810058594,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 730.868854999926,
      "epsilon_spent": 0.47606131511779515,
      "total_epsilon": 0.47606131511779515
    },
    {
      "step": 919,
      "optim_step": 115,
      "loss": 4.620339870452881,
      "grad_norm": 22.201263427734375,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 690.3021570000192,
      "epsilon_spent": 0.476353038710269,
      "total_epsilon": 0.476353038710269
    },
    {
      "step": 927,
      "optim_step": 116,
      "loss": 3.26488995552063,
      "grad_norm": 20.98078155517578,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 690.687290000028,
      "epsilon_spent": 0.47664476230274283,
      "total_epsilon": 0.47664476230274283
    },
    {
      "step": 935,
      "optim_step": 117,
      "loss": 4.086092948913574,
      "grad_norm": 20.640798568725586,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 687.0106119999946,
      "epsilon_spent": 0.47693648589521664,
      "total_epsilon": 0.47693648589521664
    },
    {
      "step": 943,
      "optim_step": 118,
      "loss": 5.305381774902344,
      "grad_norm": 32.59566879272461,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.9262759999901,
      "epsilon_spent": 0.4772282094876905,
      "total_epsilon": 0.4772282094876905
    },
    {
      "step": 951,
      "optim_step": 119,
      "loss": 4.986265659332275,
      "grad_norm": 29.20877456665039,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.1676019999604,
      "epsilon_spent": 0.4775199330801643,
      "total_epsilon": 0.4775199330801643
    },
    {
      "step": 959,
      "optim_step": 120,
      "loss": 4.417713642120361,
      "grad_norm": 25.202171325683594,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 725.7082379999247,
      "epsilon_spent": 0.4778116566726382,
      "total_epsilon": 0.4778116566726382
    },
    {
      "step": 967,
      "optim_step": 121,
      "loss": 4.444670677185059,
      "grad_norm": 26.375473022460938,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.7801050000307,
      "epsilon_spent": 0.478103380265112,
      "total_epsilon": 0.478103380265112
    },
    {
      "step": 975,
      "optim_step": 122,
      "loss": 3.366070508956909,
      "grad_norm": 20.539670944213867,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 695.995905000018,
      "epsilon_spent": 0.4783951038575858,
      "total_epsilon": 0.4783951038575858
    },
    {
      "step": 983,
      "optim_step": 123,
      "loss": 4.811342716217041,
      "grad_norm": 23.795883178710938,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 667.729535000035,
      "epsilon_spent": 0.4786868274500597,
      "total_epsilon": 0.4786868274500597
    },
    {
      "step": 991,
      "optim_step": 124,
      "loss": 2.4524757862091064,
      "grad_norm": 14.341778755187988,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 723.4768680000343,
      "epsilon_spent": 0.4789785510425335,
      "total_epsilon": 0.4789785510425335
    },
    {
      "step": 999,
      "optim_step": 125,
      "loss": 3.5274105072021484,
      "grad_norm": 20.442476272583008,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 727.7375180000263,
      "epsilon_spent": 0.4792702746350074,
      "total_epsilon": 0.4792702746350074
    },
    {
      "step": 1007,
      "optim_step": 126,
      "loss": 4.097785472869873,
      "grad_norm": 24.69135093688965,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 711.5599410000186,
      "epsilon_spent": 0.4795619982274812,
      "total_epsilon": 0.4795619982274812
    },
    {
      "step": 1015,
      "optim_step": 127,
      "loss": 3.1763010025024414,
      "grad_norm": 24.11495590209961,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 659.8757769999111,
      "epsilon_spent": 0.479853721819955,
      "total_epsilon": 0.479853721819955
    },
    {
      "step": 1023,
      "optim_step": 128,
      "loss": 5.010019779205322,
      "grad_norm": 30.66353988647461,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.9112999999352,
      "epsilon_spent": 0.4801454454124289,
      "total_epsilon": 0.4801454454124289
    },
    {
      "step": 1031,
      "optim_step": 129,
      "loss": 2.957190752029419,
      "grad_norm": 17.306777954101562,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.0720459999648,
      "epsilon_spent": 0.4804371690049027,
      "total_epsilon": 0.4804371690049027
    },
    {
      "step": 1039,
      "optim_step": 130,
      "loss": 3.120993137359619,
      "grad_norm": 25.666118621826172,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 710.4045610000185,
      "epsilon_spent": 0.4807288925973765,
      "total_epsilon": 0.4807288925973765
    },
    {
      "step": 1047,
      "optim_step": 131,
      "loss": 3.2527201175689697,
      "grad_norm": 23.425142288208008,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 731.4861410000049,
      "epsilon_spent": 0.48102061618985037,
      "total_epsilon": 0.48102061618985037
    },
    {
      "step": 1055,
      "optim_step": 132,
      "loss": 3.3020451068878174,
      "grad_norm": 20.78874969482422,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.7511509999349,
      "epsilon_spent": 0.4813123397823242,
      "total_epsilon": 0.4813123397823242
    },
    {
      "step": 1063,
      "optim_step": 133,
      "loss": 4.5404839515686035,
      "grad_norm": 28.05968475341797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.2600219999713,
      "epsilon_spent": 0.481604063374798,
      "total_epsilon": 0.481604063374798
    },
    {
      "step": 1071,
      "optim_step": 134,
      "loss": 4.569473743438721,
      "grad_norm": 28.40019416809082,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 657.1493610000516,
      "epsilon_spent": 0.48189578696727187,
      "total_epsilon": 0.48189578696727187
    },
    {
      "step": 1079,
      "optim_step": 135,
      "loss": 2.420440435409546,
      "grad_norm": 14.631410598754883,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 708.9777050000521,
      "epsilon_spent": 0.4821875105597457,
      "total_epsilon": 0.4821875105597457
    },
    {
      "step": 1087,
      "optim_step": 136,
      "loss": 4.06848669052124,
      "grad_norm": 20.469465255737305,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 700.737049000054,
      "epsilon_spent": 0.48247923415221955,
      "total_epsilon": 0.48247923415221955
    },
    {
      "step": 1095,
      "optim_step": 137,
      "loss": 3.5889365673065186,
      "grad_norm": 22.598989486694336,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 721.1324830000194,
      "epsilon_spent": 0.48277095774469336,
      "total_epsilon": 0.48277095774469336
    },
    {
      "step": 1103,
      "optim_step": 138,
      "loss": 4.00441312789917,
      "grad_norm": 19.058521270751953,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 707.5628080000342,
      "epsilon_spent": 0.4830626813371672,
      "total_epsilon": 0.4830626813371672
    },
    {
      "step": 1111,
      "optim_step": 139,
      "loss": 5.233043193817139,
      "grad_norm": 28.172218322753906,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 703.1105610000168,
      "epsilon_spent": 0.48335440492964105,
      "total_epsilon": 0.48335440492964105
    },
    {
      "step": 1119,
      "optim_step": 140,
      "loss": 2.9128010272979736,
      "grad_norm": 17.211252212524414,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 708.8622679999617,
      "epsilon_spent": 0.48364612852211486,
      "total_epsilon": 0.48364612852211486
    },
    {
      "step": 1127,
      "optim_step": 141,
      "loss": 3.9965250492095947,
      "grad_norm": 21.828083038330078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.7054609999559,
      "epsilon_spent": 0.48393785211458873,
      "total_epsilon": 0.48393785211458873
    },
    {
      "step": 1135,
      "optim_step": 142,
      "loss": 1.4305816888809204,
      "grad_norm": 1.5155901908874512,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 656.9172069999922,
      "epsilon_spent": 0.48422957570706254,
      "total_epsilon": 0.48422957570706254
    },
    {
      "step": 1143,
      "optim_step": 143,
      "loss": 4.683438301086426,
      "grad_norm": 27.431713104248047,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 761.7152459999943,
      "epsilon_spent": 0.48452129929953636,
      "total_epsilon": 0.48452129929953636
    },
    {
      "step": 1151,
      "optim_step": 144,
      "loss": 4.1198930740356445,
      "grad_norm": 25.467519760131836,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 718.3686699999043,
      "epsilon_spent": 0.4848130228920102,
      "total_epsilon": 0.4848130228920102
    },
    {
      "step": 1159,
      "optim_step": 145,
      "loss": 4.988389015197754,
      "grad_norm": 25.551368713378906,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 740.599331999988,
      "epsilon_spent": 0.48510474648448404,
      "total_epsilon": 0.48510474648448404
    },
    {
      "step": 1167,
      "optim_step": 146,
      "loss": 3.5998330116271973,
      "grad_norm": 21.10336685180664,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 749.3839410000191,
      "epsilon_spent": 0.48539647007695785,
      "total_epsilon": 0.48539647007695785
    },
    {
      "step": 1175,
      "optim_step": 147,
      "loss": 5.220012664794922,
      "grad_norm": 28.836130142211914,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 738.9584689999538,
      "epsilon_spent": 0.4856881936694317,
      "total_epsilon": 0.4856881936694317
    },
    {
      "step": 1183,
      "optim_step": 148,
      "loss": 3.213226795196533,
      "grad_norm": 19.9268798828125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 805.7017450000785,
      "epsilon_spent": 0.48597991726190554,
      "total_epsilon": 0.48597991726190554
    },
    {
      "step": 1191,
      "optim_step": 149,
      "loss": 4.198544502258301,
      "grad_norm": 28.213945388793945,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 786.1979520000659,
      "epsilon_spent": 0.48627164085437935,
      "total_epsilon": 0.48627164085437935
    },
    {
      "step": 1199,
      "optim_step": 150,
      "loss": 2.9285991191864014,
      "grad_norm": 16.46073341369629,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 759.9095260000013,
      "epsilon_spent": 0.4865633644468532,
      "total_epsilon": 0.4865633644468532
    },
    {
      "step": 1207,
      "optim_step": 151,
      "loss": 5.391111373901367,
      "grad_norm": 31.908151626586914,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 775.2463959999432,
      "epsilon_spent": 0.48685508803932703,
      "total_epsilon": 0.48685508803932703
    },
    {
      "step": 1215,
      "optim_step": 152,
      "loss": 5.370061874389648,
      "grad_norm": 29.468650817871094,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 715.5986700000767,
      "epsilon_spent": 0.4871468116318009,
      "total_epsilon": 0.4871468116318009
    },
    {
      "step": 1223,
      "optim_step": 153,
      "loss": 1.5425164699554443,
      "grad_norm": 1.4897810220718384,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 666.4609609999843,
      "epsilon_spent": 0.4874385352242747,
      "total_epsilon": 0.4874385352242747
    },
    {
      "step": 1231,
      "optim_step": 154,
      "loss": 4.501000881195068,
      "grad_norm": 29.756481170654297,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 714.0887360000079,
      "epsilon_spent": 0.48773025881674853,
      "total_epsilon": 0.48773025881674853
    },
    {
      "step": 1239,
      "optim_step": 155,
      "loss": 4.780826091766357,
      "grad_norm": 25.645076751708984,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 708.1422549999843,
      "epsilon_spent": 0.4879441601534728,
      "total_epsilon": 0.4879441601534728
    },
    {
      "step": 1247,
      "optim_step": 156,
      "loss": 3.7005844116210938,
      "grad_norm": 23.559587478637695,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.3232819999712,
      "epsilon_spent": 0.4881211094538255,
      "total_epsilon": 0.4881211094538255
    },
    {
      "step": 1255,
      "optim_step": 157,
      "loss": 2.7077624797821045,
      "grad_norm": 18.884899139404297,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.6836400000511,
      "epsilon_spent": 0.48829805875417814,
      "total_epsilon": 0.48829805875417814
    },
    {
      "step": 1263,
      "optim_step": 158,
      "loss": 4.229896068572998,
      "grad_norm": 22.191513061523438,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 709.7272720000092,
      "epsilon_spent": 0.4884750080545308,
      "total_epsilon": 0.4884750080545308
    },
    {
      "step": 1271,
      "optim_step": 159,
      "loss": 3.496122360229492,
      "grad_norm": 23.259862899780273,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 703.4013699999377,
      "epsilon_spent": 0.4886519573548835,
      "total_epsilon": 0.4886519573548835
    },
    {
      "step": 1279,
      "optim_step": 160,
      "loss": 4.969107627868652,
      "grad_norm": 29.388479232788086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 702.1997589999955,
      "epsilon_spent": 0.48882890665523615,
      "total_epsilon": 0.48882890665523615
    },
    {
      "step": 1287,
      "optim_step": 161,
      "loss": 1.4220691919326782,
      "grad_norm": 7.550929546356201,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.6901830000015,
      "epsilon_spent": 0.4890058559555888,
      "total_epsilon": 0.4890058559555888
    },
    {
      "step": 1295,
      "optim_step": 162,
      "loss": 2.961178779602051,
      "grad_norm": 14.77769660949707,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.9252000000242,
      "epsilon_spent": 0.4891828052559415,
      "total_epsilon": 0.4891828052559415
    },
    {
      "step": 1303,
      "optim_step": 163,
      "loss": 4.550004005432129,
      "grad_norm": 24.84706687927246,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.2354129999685,
      "epsilon_spent": 0.48935975455629416,
      "total_epsilon": 0.48935975455629416
    },
    {
      "step": 1311,
      "optim_step": 164,
      "loss": 4.179076671600342,
      "grad_norm": 22.583600997924805,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.444303000012,
      "epsilon_spent": 0.4895367038566468,
      "total_epsilon": 0.4895367038566468
    },
    {
      "step": 1319,
      "optim_step": 165,
      "loss": 3.4839751720428467,
      "grad_norm": 15.19767951965332,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 703.1738489999952,
      "epsilon_spent": 0.4897136531569995,
      "total_epsilon": 0.4897136531569995
    },
    {
      "step": 1327,
      "optim_step": 166,
      "loss": 5.6126532554626465,
      "grad_norm": 34.795719146728516,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.5772980000038,
      "epsilon_spent": 0.48989060245735216,
      "total_epsilon": 0.48989060245735216
    },
    {
      "step": 1335,
      "optim_step": 167,
      "loss": 3.5393829345703125,
      "grad_norm": 21.869474411010742,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 702.1023990000685,
      "epsilon_spent": 0.49006755175770483,
      "total_epsilon": 0.49006755175770483
    },
    {
      "step": 1343,
      "optim_step": 168,
      "loss": 4.103552341461182,
      "grad_norm": 24.986299514770508,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 709.1334859999279,
      "epsilon_spent": 0.4902445010580575,
      "total_epsilon": 0.4902445010580575
    },
    {
      "step": 1351,
      "optim_step": 169,
      "loss": 2.4559149742126465,
      "grad_norm": 16.547653198242188,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 703.8954150000336,
      "epsilon_spent": 0.49042145035841017,
      "total_epsilon": 0.49042145035841017
    },
    {
      "step": 1359,
      "optim_step": 170,
      "loss": 3.833824872970581,
      "grad_norm": 20.82892417907715,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 708.1598530000974,
      "epsilon_spent": 0.49059839965876284,
      "total_epsilon": 0.49059839965876284
    },
    {
      "step": 1367,
      "optim_step": 171,
      "loss": 4.676241874694824,
      "grad_norm": 24.639928817749023,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 703.2543979998991,
      "epsilon_spent": 0.4907753489591155,
      "total_epsilon": 0.4907753489591155
    },
    {
      "step": 1375,
      "optim_step": 172,
      "loss": 4.320423126220703,
      "grad_norm": 25.686738967895508,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 700.96512300006,
      "epsilon_spent": 0.4909522982594682,
      "total_epsilon": 0.4909522982594682
    },
    {
      "step": 1383,
      "optim_step": 173,
      "loss": 2.9273977279663086,
      "grad_norm": 16.820802688598633,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 697.1124300000611,
      "epsilon_spent": 0.49112924755982085,
      "total_epsilon": 0.49112924755982085
    },
    {
      "step": 1391,
      "optim_step": 174,
      "loss": 4.442744731903076,
      "grad_norm": 16.724966049194336,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.754413000046,
      "epsilon_spent": 0.4913061968601735,
      "total_epsilon": 0.4913061968601735
    },
    {
      "step": 1399,
      "optim_step": 175,
      "loss": 1.9594184160232544,
      "grad_norm": 6.9647603034973145,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 701.8606839999393,
      "epsilon_spent": 0.4914831461605262,
      "total_epsilon": 0.4914831461605262
    },
    {
      "step": 1407,
      "optim_step": 176,
      "loss": 4.682516574859619,
      "grad_norm": 26.23225212097168,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 698.1715350000286,
      "epsilon_spent": 0.49166009546087885,
      "total_epsilon": 0.49166009546087885
    },
    {
      "step": 1415,
      "optim_step": 177,
      "loss": 4.641345024108887,
      "grad_norm": 27.185880661010742,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.1053069999161,
      "epsilon_spent": 0.4918370447612315,
      "total_epsilon": 0.4918370447612315
    },
    {
      "step": 1423,
      "optim_step": 178,
      "loss": 1.8362514972686768,
      "grad_norm": 6.093571186065674,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 701.9795619999059,
      "epsilon_spent": 0.4920139940615842,
      "total_epsilon": 0.4920139940615842
    },
    {
      "step": 1431,
      "optim_step": 179,
      "loss": 2.8457624912261963,
      "grad_norm": 19.478971481323242,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.8286540000154,
      "epsilon_spent": 0.49219094336193686,
      "total_epsilon": 0.49219094336193686
    },
    {
      "step": 1439,
      "optim_step": 180,
      "loss": 4.656631946563721,
      "grad_norm": 23.399309158325195,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 708.2604559998344,
      "epsilon_spent": 0.49236789266228953,
      "total_epsilon": 0.49236789266228953
    },
    {
      "step": 1447,
      "optim_step": 181,
      "loss": 4.08886194229126,
      "grad_norm": 23.36209487915039,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 791.0813690000396,
      "epsilon_spent": 0.4925448419626422,
      "total_epsilon": 0.4925448419626422
    },
    {
      "step": 1455,
      "optim_step": 182,
      "loss": 3.4202628135681152,
      "grad_norm": 19.551319122314453,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 740.3275810002015,
      "epsilon_spent": 0.49272179126299487,
      "total_epsilon": 0.49272179126299487
    },
    {
      "step": 1463,
      "optim_step": 183,
      "loss": 3.7424135208129883,
      "grad_norm": 23.009130477905273,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 751.4945909999824,
      "epsilon_spent": 0.49289874056334754,
      "total_epsilon": 0.49289874056334754
    },
    {
      "step": 1471,
      "optim_step": 184,
      "loss": 3.406426191329956,
      "grad_norm": 20.364118576049805,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 740.214480999839,
      "epsilon_spent": 0.4930756898637002,
      "total_epsilon": 0.4930756898637002
    },
    {
      "step": 1479,
      "optim_step": 185,
      "loss": 4.655575275421143,
      "grad_norm": 19.587499618530273,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 740.44116999994,
      "epsilon_spent": 0.4932526391640529,
      "total_epsilon": 0.4932526391640529
    },
    {
      "step": 1487,
      "optim_step": 186,
      "loss": 3.787825107574463,
      "grad_norm": 23.93239402770996,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 787.33814300017,
      "epsilon_spent": 0.49342958846440554,
      "total_epsilon": 0.49342958846440554
    },
    {
      "step": 1495,
      "optim_step": 187,
      "loss": 3.240898847579956,
      "grad_norm": 19.149866104125977,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 777.8008830000545,
      "epsilon_spent": 0.4936065377647582,
      "total_epsilon": 0.4936065377647582
    },
    {
      "step": 1503,
      "optim_step": 188,
      "loss": 4.670492172241211,
      "grad_norm": 21.643617630004883,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 769.0634969999337,
      "epsilon_spent": 0.4937834870651109,
      "total_epsilon": 0.4937834870651109
    },
    {
      "step": 1511,
      "optim_step": 189,
      "loss": 4.9383864402771,
      "grad_norm": 26.703414916992188,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 729.0811790001044,
      "epsilon_spent": 0.49396043636546355,
      "total_epsilon": 0.49396043636546355
    },
    {
      "step": 1519,
      "optim_step": 190,
      "loss": 4.3997368812561035,
      "grad_norm": 27.21913719177246,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 735.3430680000201,
      "epsilon_spent": 0.4941373856658162,
      "total_epsilon": 0.4941373856658162
    },
    {
      "step": 1527,
      "optim_step": 191,
      "loss": 3.8249733448028564,
      "grad_norm": 22.96852684020996,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 713.0520539999452,
      "epsilon_spent": 0.4943143349661689,
      "total_epsilon": 0.4943143349661689
    },
    {
      "step": 1535,
      "optim_step": 192,
      "loss": 3.742595911026001,
      "grad_norm": 20.1940860748291,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 717.545083999994,
      "epsilon_spent": 0.49449128426652156,
      "total_epsilon": 0.49449128426652156
    },
    {
      "step": 1543,
      "optim_step": 193,
      "loss": 2.7900660037994385,
      "grad_norm": 17.796369552612305,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 718.3478800000103,
      "epsilon_spent": 0.4946682335668742,
      "total_epsilon": 0.4946682335668742
    },
    {
      "step": 1551,
      "optim_step": 194,
      "loss": 3.297689199447632,
      "grad_norm": 24.769081115722656,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 715.8833600001344,
      "epsilon_spent": 0.4948451828672269,
      "total_epsilon": 0.4948451828672269
    },
    {
      "step": 1559,
      "optim_step": 195,
      "loss": 1.8932641744613647,
      "grad_norm": 1.6653162240982056,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 657.5622010000188,
      "epsilon_spent": 0.49502213216757956,
      "total_epsilon": 0.49502213216757956
    },
    {
      "step": 1567,
      "optim_step": 196,
      "loss": 3.877756118774414,
      "grad_norm": 19.728715896606445,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.663479000099,
      "epsilon_spent": 0.49519908146793223,
      "total_epsilon": 0.49519908146793223
    },
    {
      "step": 1575,
      "optim_step": 197,
      "loss": 5.053391456604004,
      "grad_norm": 32.55767059326172,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 707.8529220000291,
      "epsilon_spent": 0.4953760307682849,
      "total_epsilon": 0.4953760307682849
    },
    {
      "step": 1583,
      "optim_step": 198,
      "loss": 3.6003668308258057,
      "grad_norm": 23.635622024536133,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 709.3710050000936,
      "epsilon_spent": 0.49555298006863757,
      "total_epsilon": 0.49555298006863757
    },
    {
      "step": 1591,
      "optim_step": 199,
      "loss": 1.9274821281433105,
      "grad_norm": 1.5466187000274658,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 657.0014160001847,
      "epsilon_spent": 0.49572992936899024,
      "total_epsilon": 0.49572992936899024
    },
    {
      "step": 1599,
      "optim_step": 200,
      "loss": 4.2784013748168945,
      "grad_norm": 19.79958724975586,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 716.1896580000757,
      "epsilon_spent": 0.4959068786693429,
      "total_epsilon": 0.4959068786693429
    },
    {
      "step": 1607,
      "optim_step": 201,
      "loss": 4.469797611236572,
      "grad_norm": 27.004924774169922,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 698.5985640001218,
      "epsilon_spent": 0.4960838279696956,
      "total_epsilon": 0.4960838279696956
    },
    {
      "step": 1615,
      "optim_step": 202,
      "loss": 4.394146919250488,
      "grad_norm": 26.3165283203125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 708.6819539999851,
      "epsilon_spent": 0.49626077727004825,
      "total_epsilon": 0.49626077727004825
    },
    {
      "step": 1623,
      "optim_step": 203,
      "loss": 3.136861801147461,
      "grad_norm": 17.41718292236328,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 708.4731400000237,
      "epsilon_spent": 0.4964377265704009,
      "total_epsilon": 0.4964377265704009
    },
    {
      "step": 1631,
      "optim_step": 204,
      "loss": 4.756469249725342,
      "grad_norm": 24.9771728515625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.1325560000569,
      "epsilon_spent": 0.4966146758707536,
      "total_epsilon": 0.4966146758707536
    },
    {
      "step": 1639,
      "optim_step": 205,
      "loss": 5.595344066619873,
      "grad_norm": 30.177297592163086,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 703.1226660001266,
      "epsilon_spent": 0.49679162517110625,
      "total_epsilon": 0.49679162517110625
    },
    {
      "step": 1647,
      "optim_step": 206,
      "loss": 4.2842912673950195,
      "grad_norm": 21.58463478088379,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 697.62159600009,
      "epsilon_spent": 0.4969685744714589,
      "total_epsilon": 0.4969685744714589
    },
    {
      "step": 1655,
      "optim_step": 207,
      "loss": 2.456376314163208,
      "grad_norm": 10.219172477722168,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 699.9495430000024,
      "epsilon_spent": 0.4971455237718116,
      "total_epsilon": 0.4971455237718116
    },
    {
      "step": 1663,
      "optim_step": 208,
      "loss": 4.106881618499756,
      "grad_norm": 22.180349349975586,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.4923220000783,
      "epsilon_spent": 0.49732247307216426,
      "total_epsilon": 0.49732247307216426
    },
    {
      "step": 1671,
      "optim_step": 209,
      "loss": 4.052673816680908,
      "grad_norm": 26.62446403503418,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 714.9691429999621,
      "epsilon_spent": 0.49749942237251693,
      "total_epsilon": 0.49749942237251693
    },
    {
      "step": 1679,
      "optim_step": 210,
      "loss": 4.141384124755859,
      "grad_norm": 18.09674644470215,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.9288189998133,
      "epsilon_spent": 0.4976763716728696,
      "total_epsilon": 0.4976763716728696
    },
    {
      "step": 1687,
      "optim_step": 211,
      "loss": 4.726698875427246,
      "grad_norm": 26.55084228515625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 710.6450650001079,
      "epsilon_spent": 0.49785332097322227,
      "total_epsilon": 0.49785332097322227
    },
    {
      "step": 1695,
      "optim_step": 212,
      "loss": 3.2207870483398438,
      "grad_norm": 21.098663330078125,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 707.7644339999551,
      "epsilon_spent": 0.49803027027357494,
      "total_epsilon": 0.49803027027357494
    },
    {
      "step": 1703,
      "optim_step": 213,
      "loss": 3.637725591659546,
      "grad_norm": 25.4545955657959,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 702.2270510001363,
      "epsilon_spent": 0.4982072195739276,
      "total_epsilon": 0.4982072195739276
    },
    {
      "step": 1711,
      "optim_step": 214,
      "loss": 4.038358688354492,
      "grad_norm": 22.78097152709961,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.3057180001142,
      "epsilon_spent": 0.4983841688742803,
      "total_epsilon": 0.4983841688742803
    },
    {
      "step": 1719,
      "optim_step": 215,
      "loss": 4.402238368988037,
      "grad_norm": 27.163082122802734,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.8348970001825,
      "epsilon_spent": 0.49856111817463294,
      "total_epsilon": 0.49856111817463294
    },
    {
      "step": 1727,
      "optim_step": 216,
      "loss": 1.6866081953048706,
      "grad_norm": 9.510716438293457,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 699.8224179999397,
      "epsilon_spent": 0.4987380674749856,
      "total_epsilon": 0.4987380674749856
    },
    {
      "step": 1735,
      "optim_step": 217,
      "loss": 4.111320972442627,
      "grad_norm": 28.92652702331543,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 696.369316000073,
      "epsilon_spent": 0.4989150167753383,
      "total_epsilon": 0.4989150167753383
    },
    {
      "step": 1743,
      "optim_step": 218,
      "loss": 5.450395584106445,
      "grad_norm": 31.227981567382812,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 699.4788199999675,
      "epsilon_spent": 0.49909196607569095,
      "total_epsilon": 0.49909196607569095
    },
    {
      "step": 1751,
      "optim_step": 219,
      "loss": 3.7537283897399902,
      "grad_norm": 18.437213897705078,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 707.8788710000481,
      "epsilon_spent": 0.4992689153760436,
      "total_epsilon": 0.4992689153760436
    },
    {
      "step": 1759,
      "optim_step": 220,
      "loss": 3.789438486099243,
      "grad_norm": 24.079648971557617,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 656.6095209998366,
      "epsilon_spent": 0.4994458646763963,
      "total_epsilon": 0.4994458646763963
    },
    {
      "step": 1767,
      "optim_step": 221,
      "loss": 4.698474407196045,
      "grad_norm": 20.007694244384766,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 706.9259479999346,
      "epsilon_spent": 0.49962281397674896,
      "total_epsilon": 0.49962281397674896
    },
    {
      "step": 1775,
      "optim_step": 222,
      "loss": 3.8254458904266357,
      "grad_norm": 22.117719650268555,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.231607000087,
      "epsilon_spent": 0.4997997632771016,
      "total_epsilon": 0.4997997632771016
    },
    {
      "step": 1783,
      "optim_step": 223,
      "loss": 3.4460933208465576,
      "grad_norm": 25.48282241821289,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.8605409999927,
      "epsilon_spent": 0.4999767125774543,
      "total_epsilon": 0.4999767125774543
    },
    {
      "step": 1791,
      "optim_step": 224,
      "loss": 4.219425678253174,
      "grad_norm": 19.681987762451172,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 659.0294029999768,
      "epsilon_spent": 0.500153661877807,
      "total_epsilon": 0.500153661877807
    },
    {
      "step": 1799,
      "optim_step": 225,
      "loss": 3.393324851989746,
      "grad_norm": 20.811626434326172,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 709.981482999865,
      "epsilon_spent": 0.5003306111781597,
      "total_epsilon": 0.5003306111781597
    },
    {
      "step": 1807,
      "optim_step": 226,
      "loss": 2.944932699203491,
      "grad_norm": 18.133474349975586,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 723.7960559998555,
      "epsilon_spent": 0.5005075604785123,
      "total_epsilon": 0.5005075604785123
    },
    {
      "step": 1815,
      "optim_step": 227,
      "loss": 2.322641134262085,
      "grad_norm": 16.3398494720459,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.0617079999029,
      "epsilon_spent": 0.500684509778865,
      "total_epsilon": 0.500684509778865
    },
    {
      "step": 1823,
      "optim_step": 228,
      "loss": 5.679269790649414,
      "grad_norm": 30.626415252685547,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.6538370000235,
      "epsilon_spent": 0.5008614590792176,
      "total_epsilon": 0.5008614590792176
    },
    {
      "step": 1831,
      "optim_step": 229,
      "loss": 4.206685543060303,
      "grad_norm": 27.317453384399414,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 695.5969260000074,
      "epsilon_spent": 0.5010384083795704,
      "total_epsilon": 0.5010384083795704
    },
    {
      "step": 1839,
      "optim_step": 230,
      "loss": 4.883723258972168,
      "grad_norm": 24.216075897216797,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.4984059998569,
      "epsilon_spent": 0.501215357679923,
      "total_epsilon": 0.501215357679923
    },
    {
      "step": 1847,
      "optim_step": 231,
      "loss": 1.8466476202011108,
      "grad_norm": 1.5633524656295776,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 652.0195840000724,
      "epsilon_spent": 0.5013923069802757,
      "total_epsilon": 0.5013923069802757
    },
    {
      "step": 1855,
      "optim_step": 232,
      "loss": 3.265216112136841,
      "grad_norm": 24.345195770263672,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 703.2297660000495,
      "epsilon_spent": 0.5015692562806283,
      "total_epsilon": 0.5015692562806283
    },
    {
      "step": 1863,
      "optim_step": 233,
      "loss": 3.025578022003174,
      "grad_norm": 21.30794334411621,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 712.5252329999512,
      "epsilon_spent": 0.501746205580981,
      "total_epsilon": 0.501746205580981
    },
    {
      "step": 1871,
      "optim_step": 234,
      "loss": 5.368841648101807,
      "grad_norm": 30.729082107543945,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 682.5590079999984,
      "epsilon_spent": 0.5019231548813337,
      "total_epsilon": 0.5019231548813337
    },
    {
      "step": 1879,
      "optim_step": 235,
      "loss": 4.560517311096191,
      "grad_norm": 24.57698631286621,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 701.1300100000426,
      "epsilon_spent": 0.5021001041816864,
      "total_epsilon": 0.5021001041816864
    },
    {
      "step": 1887,
      "optim_step": 236,
      "loss": 3.4047539234161377,
      "grad_norm": 23.314668655395508,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.856972000016,
      "epsilon_spent": 0.502277053482039,
      "total_epsilon": 0.502277053482039
    },
    {
      "step": 1895,
      "optim_step": 237,
      "loss": 3.468911647796631,
      "grad_norm": 24.983842849731445,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 709.6236480001608,
      "epsilon_spent": 0.5024540027823917,
      "total_epsilon": 0.5024540027823917
    },
    {
      "step": 1903,
      "optim_step": 238,
      "loss": 4.166032314300537,
      "grad_norm": 20.00490379333496,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 705.2927199999885,
      "epsilon_spent": 0.5026309520827443,
      "total_epsilon": 0.5026309520827443
    },
    {
      "step": 1911,
      "optim_step": 239,
      "loss": 2.4094464778900146,
      "grad_norm": 15.17257308959961,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 716.8295769999986,
      "epsilon_spent": 0.5028079013830971,
      "total_epsilon": 0.5028079013830971
    },
    {
      "step": 1919,
      "optim_step": 240,
      "loss": 3.950394630432129,
      "grad_norm": 26.97584342956543,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 704.5700099999976,
      "epsilon_spent": 0.5029848506834497,
      "total_epsilon": 0.5029848506834497
    },
    {
      "step": 1927,
      "optim_step": 241,
      "loss": 4.740469455718994,
      "grad_norm": 27.975234985351562,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 680.9776659999898,
      "epsilon_spent": 0.5031617999838024,
      "total_epsilon": 0.5031617999838024
    },
    {
      "step": 1935,
      "optim_step": 242,
      "loss": 1.9152058362960815,
      "grad_norm": 4.315312385559082,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 720.306982000011,
      "epsilon_spent": 0.503338749284155,
      "total_epsilon": 0.503338749284155
    },
    {
      "step": 1943,
      "optim_step": 243,
      "loss": 1.7825024127960205,
      "grad_norm": 6.274134635925293,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 715.7779879998998,
      "epsilon_spent": 0.5035156985845077,
      "total_epsilon": 0.5035156985845077
    },
    {
      "step": 1951,
      "optim_step": 244,
      "loss": 1.7148491144180298,
      "grad_norm": 3.42940092086792,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 764.405823000061,
      "epsilon_spent": 0.5036926478848603,
      "total_epsilon": 0.5036926478848603
    },
    {
      "step": 1959,
      "optim_step": 245,
      "loss": 3.1171250343322754,
      "grad_norm": 21.750545501708984,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 738.7050830000135,
      "epsilon_spent": 0.5038695971852131,
      "total_epsilon": 0.5038695971852131
    },
    {
      "step": 1967,
      "optim_step": 246,
      "loss": 2.1689300537109375,
      "grad_norm": 1.680890440940857,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 643.3235380000042,
      "epsilon_spent": 0.5040465464855657,
      "total_epsilon": 0.5040465464855657
    },
    {
      "step": 1975,
      "optim_step": 247,
      "loss": 4.392202377319336,
      "grad_norm": 23.76410675048828,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 779.9539850000201,
      "epsilon_spent": 0.5042234957859184,
      "total_epsilon": 0.5042234957859184
    },
    {
      "step": 1983,
      "optim_step": 248,
      "loss": 4.203093528747559,
      "grad_norm": 24.985504150390625,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 783.2229470000129,
      "epsilon_spent": 0.504400445086271,
      "total_epsilon": 0.504400445086271
    },
    {
      "step": 1991,
      "optim_step": 249,
      "loss": 5.009641170501709,
      "grad_norm": 29.200302124023438,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 760.7966579998902,
      "epsilon_spent": 0.5045773943866237,
      "total_epsilon": 0.5045773943866237
    },
    {
      "step": 1999,
      "optim_step": 250,
      "loss": 4.469500541687012,
      "grad_norm": 27.564788818359375,
      "lr": 0.0001,
      "tokens": 512,
      "time_ms": 729.9988160000339,
      "epsilon_spent": 0.5047543436869764,
      "total_epsilon": 0.5047543436869764
    }
  ]
}