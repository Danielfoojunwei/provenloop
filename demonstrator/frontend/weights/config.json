{
  "vocab_size": 151936,
  "hidden_size": 1536,
  "num_hidden_layers": 28,
  "num_attention_heads": 12,
  "num_key_value_heads": 2,
  "intermediate_size": 8960,
  "embed_shape": [
    151936,
    1536
  ],
  "lm_head_shape": [
    151936,
    1536
  ],
  "dtype": "float16"
}